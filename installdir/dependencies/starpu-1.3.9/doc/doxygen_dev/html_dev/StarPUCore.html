<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>StarPU Internal Handbook: StarPU Core</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">StarPU Internal Handbook
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('StarPUCore.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">StarPU Core </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="CoreEntities"></a>
StarPU Core Entities</h1>
<p>TODO</p>
<h2><a class="anchor" id="CoreEntitiesOverview"></a>
Overview</h2>
<p>Execution entities:</p><ul>
<li><b>worker</b>: A worker (see <a class="el" href="StarPUCore.html#CoreEntitiesWorkers">Workers</a>, <a class="el" href="StarPUCore.html#CoreEntitiesWorkersAndContexts">Workers and Scheduling Contexts</a>) entity is a CPU thread created by StarPU to manage one computing unit. The computing unit can be a local CPU core, an accelerator or GPU device, or &mdash; on the master side when running in master-slave distributed mode &mdash; a remote slave computing node. It is responsible for querying scheduling policies for tasks to execute.</li>
<li><b>sched_context</b>: A scheduling context (see <a class="el" href="StarPUCore.html#CoreEntitiesContexts">Scheduling Contexts</a>, <a class="el" href="StarPUCore.html#CoreEntitiesWorkersAndContexts">Workers and Scheduling Contexts</a>) is a logical set of workers governed by an instance of a scheduling policy. It defines the computing units to which the scheduling policy instance may assign work entities.</li>
<li><b>driver</b>: A driver is the set of hardware-dependent routines used by a worker to initialize its associated computing unit, execute work entities on it, and finalize the computing unit usage at the end of the session.</li>
</ul>
<p>Work entities:</p><ul>
<li><b>task</b>: A task is a high level work request submitted to StarPU by the application, or internally by StarPU itself.</li>
<li><b>job</b>: A job is a low level view of a work request. It is not exposed to the application. A job structure may be shared among several task structures in the case of a parallel task.</li>
</ul>
<p>Data entities:</p><ul>
<li><b>data handle</b>: A data handle is a high-level, application opaque object designating a piece of data currently registered to the StarPU data management layer. Internally, it is a <a class="el" href="coherency_8h.html#struct__starpu__data__state">_starpu_data_state</a> structure.</li>
<li><b>data replicate</b>: A data replicate is a low-level object designating one copy of a piece of data registered to StarPU as a data handle, residing in one memory node managed by StarPU. It is not exposed to the application.</li>
</ul>
<h2><a class="anchor" id="CoreEntitiesWorkers"></a>
Workers</h2>
<p>A <b>worker</b> is a CPU thread created by StarPU. Its role is to manage one computing unit. This computing unit can be a local CPU core, in which case, the worker thread manages the actual CPU core to which it is assigned; or it can be a computing device such as a GPU or an accelerator (or even a remote computing node when StarPU is running in distributed master-slave mode.) When a worker manages a computing device, the CPU core to which the worker's thread is by default exclusively assigned to the device management work and does not participate to computation.</p>
<h3><a class="anchor" id="CoreEntitiesWorkersStates"></a>
States</h3>
<p><b>Scheduling operations related state</b></p>
<p>While a worker is conducting a scheduling operations, e.g. the worker is in the process of selecting a new task to execute, flag state_sched_op_pending is set to <code>!0</code>, otherwise it is set to <code>0</code>.</p>
<p>While state_sched_op_pending is !0, the following exhaustive list of operations on that workers are restricted in the stated way:</p>
<ul>
<li>adding the worker to a context is not allowed;</li>
<li>removing the worker from a context is not allowed;</li>
<li>adding the worker to a parallel task team is not allowed;</li>
<li>removing the worker from a parallel task team is not allowed;</li>
<li>querying state information about the worker is only allowed while <code>state_relax_refcnt &gt; 0</code>;<ul>
<li>in particular, querying whether the worker is blocked on a parallel team entry is only allowed while <code>state_relax_refcnt &gt; 0</code>.</li>
</ul>
</li>
</ul>
<p>Entering and leaving the state_sched_op_pending state is done through calls to <a class="el" href="group__workers.html#ga49cb66c64bbbc10dfbb70303c9b1faa7">_starpu_worker_enter_sched_op()</a> and _starpu_worker_leave_sched_op() respectively (see these functions in use in functions _starpu_get_worker_task() and _starpu_get_multi_worker_task()). These calls ensure that any pending conflicting operation deferred while the worker was in the state_sched_op_pending state is performed in an orderly manner.</p>
<p><br />
 <b>Scheduling contexts related states</b></p>
<p>Flag <code>state_changing_ctx_notice</code> is set to <code>!0</code> when a thread is about to add the worker to a scheduling context or remove it from a scheduling context, and is currently waiting for a safe window to do so, until the targeted worker is not in a scheduling operation or parallel task operation anymore. This flag set to <code>!0</code> will also prevent the targeted worker to attempt a fresh scheduling operation or parallel task operation to avoid starving conditions. However, a scheduling operation that was already in progress before the notice is allowed to complete.</p>
<p>Flag <code>state_changing_ctx_waiting</code> is set to <code>!0</code> when a scheduling context worker addition or removal involving the targeted worker is about to occur and the worker is currently performing a scheduling operation to tell the targeted worker that the initiator thread is waiting for the scheduling operation to complete and should be woken up upon completion.</p>
<p><br />
 <b>Relaxed synchronization related states</b></p>
<p>Any StarPU worker may participate to scheduling operations, and in this process, may be forced to observe state information from other workers. A StarPU worker thread may therefore be observed by any thread, even other StarPU workers. Since workers may observe each other in any order, it is not possible to rely exclusively on the <code>sched_mutex</code> of each worker to protect the observation of worker state flags by other workers, because worker A observing worker B would involve locking workers in (A B) sequence, while worker B observing worker A would involve locking workers in (B A) sequence, leading to lock inversion deadlocks.</p>
<p>In consequence, no thread must hold more than one worker's sched_mutex at any time. Instead, workers implement a relaxed locking scheme based on the <code>state_relax_refcnt</code> counter, itself protected by the worker's sched_mutex. When <code>state_relax_refcnt &gt; 0</code>, the targeted worker state flags may be observed, otherwise the thread attempting the observation must repeatedly wait on the targeted worker's <code>sched_cond</code> condition until <code>state_relax_refcnt &gt; 0</code>.</p>
<p>The relaxed mode, while on, can actually be seen as a transactional consistency model, where concurrent accesses are authorized and potential conflicts are resolved after the fact. When the relaxed mode is off, the consistency model becomes a mutual exclusion model, where the sched_mutex of the worker must be held in order to access or change the worker state.</p>
<p><br />
 <b>Parallel tasks related states</b></p>
<p>When a worker is scheduled to participate to the execution of a parallel task, it must wait for the whole team of workers participating to the execution of this task to be ready. While the worker waits for its teammates, it is not available to run other tasks or perform other operations. Such a waiting operation can therefore not start while conflicting operations such as scheduling operations and scheduling context resizing involving the worker are on-going. Conversely these operations and other may query weather the worker is blocked on a parallel task entry with starpu_worker_is_blocked_in_parallel().</p>
<p>The starpu_worker_is_blocked_in_parallel() function is allowed to proceed while and only while <code>state_relax_refcnt &gt; 0</code>. Due to the relaxed worker locking scheme, the <code>state_blocked_in_parallel</code> flag of the targeted worker may change after it has been observed by an observer thread. In consequence, flag <code>state_blocked_in_parallel_observed</code> of the targeted worker is set to <code>1</code> by the observer immediately after the observation to "taint" the targeted worker. The targeted worker will clear the <code>state_blocked_in_parallel_observed</code> flag tainting and defer the processing of parallel task related requests until a full scheduling operation shot completes without the <code>state_blocked_in_parallel_observed</code> flag being tainted again. The purpose of this tainting flag is to prevent parallel task operations to be started immediately after the observation of a transient scheduling state.</p>
<p>Worker's management of parallel tasks is governed by the following set of state flags and counters:</p>
<ul>
<li><code>state_blocked_in_parallel:</code> set to <code>!0</code> while the worker is currently blocked on a parallel task;</li>
<li><code>state_blocked_in_parallel_observed:</code> set to <code>!0</code> to taint the worker when a thread has observed the state_blocked_in_parallel flag of this worker while its <code>state_relax_refcnt</code> state counter was <code>&gt;0</code>. Any pending request to add or remove the worker from a parallel task team will be deferred until a whole scheduling operation shot completes without being tainted again.</li>
<li><code>state_block_in_parallel_req:</code> set to <code>!0</code> when a thread is waiting on a request for the worker to be added to a parallel task team. Must be protected by the worker's <code>sched_mutex</code>.</li>
<li><code>state_block_in_parallel_ack:</code> set to <code>!0</code> by the worker when acknowledging a request for being added to a parallel task team. Must be protected by the worker's <code>sched_mutex</code>.</li>
<li><code>state_unblock_in_parallel_req:</code> set to <code>!0</code> when a thread is waiting on a request for the worker to be removed from a parallel task team. Must be protected by the worker's <code>sched_mutex</code>.</li>
<li><code>state_unblock_in_parallel_ack:</code> set to <code>!0</code> by the worker when acknowledging a request for being removed from a parallel task team. Must be protected by the worker's <code>sched_mutex</code>.</li>
<li><code>block_in_parallel_ref_count:</code> counts the number of consecutive pending requests to enter parallel task teams. Only the first of a train of requests for entering parallel task teams triggers the transition of the <code>state_block_in_parallel_req</code> flag from <code>0</code> to <code>1</code>. Only the last of a train of requests to leave a parallel task team triggers the transition of flag <code>state_unblock_in_parallel_req</code> from <code>0</code> to <code>1</code>. Must be protected by the worker's <code>sched_mutex</code>.</li>
</ul>
<h3><a class="anchor" id="CoreEntitiesWorkersOperations"></a>
Operations</h3>
<p><b>Entry point</b></p>
<p>All the operations of a worker are handled in an iterative fashion, either by the application code on a thread launched by the application, or automatically by StarPU on a device-dependent CPU thread launched by StarPU. Whether a worker's operation cycle is managed automatically or not is controlled per session by the field <code>not_launched_drivers</code> of the <code>starpu_conf</code> struct, and is decided in _starpu_launch_drivers() function.</p>
<p>When managed automatically, cycles of operations for a worker are handled by the corresponding driver specific <code>_starpu_&lt;DRV&gt;_worker()</code> function, where <code>DRV</code> is a driver name such as cpu (<code>_starpu_cpu_worker</code>) or cuda (<code>_starpu_cuda_worker</code>), for instance. Otherwise, the application must supply a thread which will repeatedly call starpu_driver_run_once() for the corresponding worker.</p>
<p>In both cases, control is then transferred to _starpu_cpu_driver_run_once() (or the corresponding driver specific func). The cycle of operations typically includes, at least, the following operations:</p>
<ul>
<li><b>task scheduling</b></li>
<li><b>parallel task team build-up</b></li>
<li><b>task input processing</b></li>
<li><b>data transfer processing</b></li>
<li><b>task execution</b></li>
</ul>
<p>When the worker cycles are handled by StarPU automatically, the iterative operation processing ends when the <code>running</code> field of <code>_starpu_config</code> becomes false. This field should not be read directly, instead it should be read through the <a class="el" href="group__workers.html#ga9995b5383955f266fb787ccf515d7ef3">_starpu_machine_is_running()</a> function.</p>
<p><br />
 <b>Task scheduling</b></p>
<p>If the worker does not yet have a queued task, it calls _starpu_get_worker_task() to try and obtain a task. This may involve scheduling operations such as stealing a queued but not yet executed task from another worker. The operation may not necessarily succeed if no tasks are ready and/or suitable to run on the worker's computing unit.</p>
<p><br />
 <b>Parallel task team build-up</b></p>
<p>If the worker has a task ready to run and the corresponding job has a size <code>&gt;1</code>, then the task is a parallel job and the worker must synchronize with the other workers participating to the parallel execution of the job to assign a unique rank for each worker. The synchronization is done through the job's <code>sync_mutex</code> mutex.</p>
<p><br />
 <b>Task input processing</b></p>
<p>Before the task can be executed, its input data must be made available on a memory node reachable by the worker's computing unit. To do so, the worker calls _starpu_fetch_task_input()</p>
<p><br />
 <b>Data transfer processing</b></p>
<p>The worker makes pending data transfers (involving memory node(s) that it is driving) progress, with a call to __starpu_datawizard_progress(),</p>
<p><br />
 <b>Task execution</b></p>
<p>Once the worker has a pending task assigned and the input data for that task are available in the memory node reachable by the worker's computing unit, the worker calls _starpu_cpu_driver_execute_task() (or the corresponding driver specific function) to proceed to the execution of the task.</p>
<h2><a class="anchor" id="CoreEntitiesContexts"></a>
Scheduling Contexts</h2>
<p>A scheduling context is a logical set of workers governed by an instance of a scheduling policy. Tasks submitted to a given scheduling context are confined to the computing units governed by the workers belonging to this scheduling context at the time they get scheduled.</p>
<p>A scheduling context is identified by an unsigned integer identifier between <code>0</code> and <code>STARPU_NMAX_SCHED_CTXS - 1</code>. The <code>STARPU_NMAX_SCHED_CTXS</code> identifier value is reserved to indicated an unallocated, invalid or deleted scheduling context.</p>
<p>Accesses to the scheduling context structure are governed by a multiple-readers/single-writer lock (<code>rwlock</code> field). Changes to the structure contents, additions or removals of workers, statistics updates, all must be done with proper exclusive write access.</p>
<h2><a class="anchor" id="CoreEntitiesWorkersAndContexts"></a>
Workers and Scheduling Contexts</h2>
<p>A worker can be assigned to one or more <b>scheduling contexts</b>. It exclusively receives tasks submitted to the scheduling context(s) it is currently assigned at the time such tasks are scheduled. A worker may add itself to or remove itself from a scheduling context.</p>
<p><br />
 <b>Locking and synchronization rules between workers and scheduling contexts</b></p>
<p>A thread currently holding a worker sched_mutex must not attempt to acquire a scheduling context rwlock, neither for writing nor for reading. Such an attempt constitutes a lock inversion and may result in a deadlock.</p>
<p>A worker currently in a scheduling operation must enter the relaxed state before attempting to acquire a scheduling context rwlock, either for reading or for writing.</p>
<p>When the set of workers assigned to a scheduling context is about to be modified, all the workers in the union between the workers belonging to the scheduling context before the change and the workers expected to belong to the scheduling context after the change must be notified using the notify_workers_about_changing_ctx_pending() function prior to the update. After the update, all the workers in that same union must be notified for the update completion with a call to notify_workers_about_changing_ctx_done().</p>
<p>The function notify_workers_about_changing_ctx_pending() places every worker passed in argument in a state compatible with changing the scheduling context assignment of that worker, possibly blocking until that worker leaves incompatible states such as a pending scheduling operation. If the caller of <code>notify_workers_about_changing_ctx_pending()</code> is itself a worker included in the set of workers passed in argument, it does not notify itself, with the assumption that the worker is already calling <code>notify_workers_about_changing_ctx_pending()</code> from a state compatible with a scheduling context assignment update. Once a worker has been notified about a scheduling context change pending, it cannot proceed with incompatible operations such as a scheduling operation until it receives a notification that the context update operation is complete.</p>
<h2><a class="anchor" id="CoreEntitiesDrivers"></a>
Drivers</h2>
<p>Each driver defines a set of routines depending on some specific hardware. These routines include hardware discovery/initialization, task execution, device memory management and data transfers.</p>
<p>While most hardware dependent routines are in source files located in the <code>/src/drivers</code> subdirectory of the StarPU tree, some can be found elsewhere in the tree such as <code>src/datawizard/malloc.c</code> for memory allocation routines or the subdirectories of <code>src/datawizard/interfaces/</code> for data transfer routines.</p>
<p>The driver ABI defined in the <a class="el" href="struct__starpu__driver__ops.html">_starpu_driver_ops</a> structure includes the following operations:</p>
<ul>
<li><code></code>.init: initialize a driver instance for the calling worker managing a hardware computing unit compatible with this driver.</li>
<li><code></code>.run_once: perform a single driver progress cycle for the calling worker (see <a class="el" href="StarPUCore.html#CoreEntitiesWorkersOperations">Operations</a>).</li>
<li><code></code>.deinit: deinitialize the driver instance for the calling worker</li>
<li><code></code>.run: executes the following sequence automatically: call <code></code>.init, repeatedly call <code></code>.run_once until the function <a class="el" href="group__workers.html#ga9995b5383955f266fb787ccf515d7ef3">_starpu_machine_is_running()</a> returns false, call <code></code>.deinit.</li>
</ul>
<p>The source code common to all drivers is shared in <code>src/drivers/driver_common/driver_common.[ch]</code>. This file includes services such as grabbing a new task to execute on a worker, managing statistics accounting on job startup and completion and updating the worker status</p>
<h3><a class="anchor" id="CoreEntitiesDriversMP"></a>
Master/Slave Drivers</h3>
<p>A subset of the drivers corresponds to drivers managing computing units in master/slave mode, that is, drivers involving a local master instance managing one or more remote slave instances on the targeted device(s). This includes devices such as discrete manycore accelerators (e.g. Intel's Knight Corners board, for instance), or pseudo devices such as a cluster of cpu nodes driver through StarPU's MPI master/slave mode. A driver instance on the master side is named the <b>source</b>, while a driver instances on the slave side is named the <b>sink</b>.</p>
<p>A significant part of the work realized on the source and sink sides of master/slave drivers is identical among all master/slave drivers, due to the similarities in the software pattern. Therefore, many routines are shared among all these drivers in the <code>src/drivers/mp_common</code> subdirectory. In particular, a set of default commands to be used between sources and sinks is defined, assuming the availability of some communication channel between them (see enum _starpu_mp_command)</p>
<p>TODO</p>
<h2><a class="anchor" id="CoreEntitiesTasksJobs"></a>
Tasks and Jobs</h2>
<p>TODO</p>
<h2><a class="anchor" id="CoreEntitiesData"></a>
Data</h2>
<p>TODO </p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Fri Oct 22 2021 15:02:50 for StarPU Internal Handbook by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
