<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>StarPU Handbook: Check List When Performance Are Not There</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">StarPU Handbook
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('CheckListWhenPerformanceAreNotThere.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Check List When Performance Are Not There </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>TODO: improve!</p>
<p>To achieve good performance, we give below a list of features which should be checked.</p>
<p>For a start, you can use <a class="el" href="OfflinePerformanceTools.html">Offline Performance Tools</a> to get a Gantt chart which will show roughly where time is spent, and focus correspondingly.</p>
<h1><a class="anchor" id="CheckTaskSize"></a>
Check Task Size</h1>
<p>Make sure that your tasks are not too small, as the StarPU runtime overhead is not completely zero. As explained in <a class="el" href="BuildingAndInstallingStarPU.html#TaskSizeOverhead">Task Size Overhead</a>, you can run the script <code>tasks_size_overhead.sh</code> to get an idea of the scalability of tasks depending on their duration (in µs), on your own system.</p>
<p>Typically, 10µs-ish tasks are definitely too small, the CUDA overhead itself is much bigger than this.</p>
<p>1ms-ish tasks may be a good start, but will not necessarily scale to many dozens of cores, so it's better to try to get 10ms-ish tasks.</p>
<p>Tasks durations can easily be observed when performance models are defined (see <a class="el" href="OnlinePerformanceTools.html#PerformanceModelExample">Performance Model Example</a>) by using the tools <code>starpu_perfmodel_plot</code> or <code>starpu_perfmodel_display</code> (see <a class="el" href="OfflinePerformanceTools.html#PerformanceOfCodelets">Performance Of Codelets</a>)</p>
<p>When using parallel tasks, the problem is even worse since StarPU has to synchronize the tasks execution.</p>
<h1><a class="anchor" id="ConfigurationImprovePerformance"></a>
Configuration Which May Improve Performance</h1>
<p>If you do not plan to use support for GPUs or out-of-core, i.e. not use StarPU's ability to manage data coherency between several memory nodes, the <code>configure</code> option <a class="el" href="CompilationConfiguration.html#enable-maxnodes">--enable-maxnodes=1</a> allows to considerably reduce StarPU's memory management overhead.</p>
<p>The <code>configure</code> option <a class="el" href="CompilationConfiguration.html#enable-fast">--enable-fast</a> disables all assertions. This makes StarPU more performant for really small tasks by disabling all sanity checks. Only use this for measurements and production, not for development, since this will drop all basic checks.</p>
<h1><a class="anchor" id="DataRelatedFeaturesToImprovePerformance"></a>
Data Related Features Which May Improve Performance</h1>
<p>link to <a class="el" href="DataManagement.html#DataManagement">Data Management</a></p>
<p>link to <a class="el" href="DataManagement.html#DataPrefetch">Data Prefetch</a></p>
<h1><a class="anchor" id="TaskRelatedFeaturesToImprovePerformance"></a>
Task Related Features Which May Improve Performance</h1>
<p>link to <a class="el" href="TasksInStarPU.html#TaskGranularity">Task Granularity</a></p>
<p>link to <a class="el" href="TasksInStarPU.html#TaskSubmission">Task Submission</a></p>
<p>link to <a class="el" href="TasksInStarPU.html#TaskPriorities">Task Priorities</a></p>
<h1><a class="anchor" id="SchedulingRelatedFeaturesToImprovePerformance"></a>
Scheduling Related Features Which May Improve Performance</h1>
<p>link to <a class="el" href="Scheduling.html#TaskSchedulingPolicy">Task Scheduling Policies</a></p>
<p>link to <a class="el" href="Scheduling.html#TaskDistributionVsDataTransfer">Task Distribution Vs Data Transfer</a></p>
<p>link to <a class="el" href="Scheduling.html#Energy-basedScheduling">Energy-based Scheduling</a></p>
<p>link to <a class="el" href="Scheduling.html#StaticScheduling">Static Scheduling</a></p>
<h1><a class="anchor" id="CUDA-specificOptimizations"></a>
CUDA-specific Optimizations</h1>
<p>For proper overlapping of asynchronous GPU data transfers, data has to be pinned by CUDA. Data allocated with <a class="el" href="group__API__Standard__Memory__Library.html#ga49603eaea3b05e8ced9ba1bd873070c3">starpu_malloc()</a> is always properly pinned. If the application registers to StarPU some data which has not been allocated with <a class="el" href="group__API__Standard__Memory__Library.html#ga49603eaea3b05e8ced9ba1bd873070c3">starpu_malloc()</a>, <a class="el" href="group__API__Standard__Memory__Library.html#ga5a6ea6d03d7b0f4a97a8046b30ecd0bb">starpu_memory_pin()</a> should be called to pin the data memory.</p>
<p>Due to CUDA limitations, StarPU will have a hard time overlapping its own communications and the codelet computations if the application does not use a dedicated CUDA stream for its computations instead of the default stream, which synchronizes all operations of the GPU. The function <a class="el" href="group__API__CUDA__Extensions.html#gad7d80d054bd2b9570e1d7e24442e19c0">starpu_cuda_get_local_stream()</a> returns a stream which can be used by all CUDA codelet operations to avoid this issue. For instance:</p>
<div class="fragment"><div class="line">func &lt;&lt;&lt;grid,block,0,starpu_cuda_get_local_stream()&gt;&gt;&gt; (foo, bar);</div><div class="line">cudaError_t status = cudaGetLastError();</div><div class="line"><span class="keywordflow">if</span> (status != cudaSuccess) <a class="code" href="group__API__CUDA__Extensions.html#gae30cd6ebde1dc4001ae8a17cabd5dbc4">STARPU_CUDA_REPORT_ERROR</a>(status);</div><div class="line">cudaStreamSynchronize(<a class="code" href="group__API__CUDA__Extensions.html#gad7d80d054bd2b9570e1d7e24442e19c0">starpu_cuda_get_local_stream</a>());</div></div><!-- fragment --><p>as well as the use of <code>cudaMemcpyAsync()</code>, etc. for each CUDA operation one needs to use a version that takes the a stream parameter.</p>
<p>If the kernel uses its own non-default stream, one can synchronize this stream with the StarPU-provided stream this way:</p>
<div class="fragment"><div class="line">cudaEvent_t event;</div><div class="line">call_kernel_with_its_own_stream()</div><div class="line">cudaEventCreateWithFlags(&amp;event, cudaEventDisableTiming);</div><div class="line">cudaEventRecord(event, get_kernel_stream());</div><div class="line">cudaStreamWaitEvent(<a class="code" href="group__API__CUDA__Extensions.html#gad7d80d054bd2b9570e1d7e24442e19c0">starpu_cuda_get_local_stream</a>(), event, 0);</div><div class="line">cudaEventDestroy(event);</div></div><!-- fragment --><p>This code makes the StarPU-provided stream wait for a new event, which will be triggered by the completion of the kernel.</p>
<p>Unfortunately, some CUDA libraries do not have stream variants of kernels. This will seriously lower the potential for overlapping. If some CUDA calls are made without specifying this local stream, synchronization needs to be explicited with cudaDeviceSynchronize() around these calls, to make sure that they get properly synchronized with the calls using the local stream. Notably, <code>cudaMemcpy()</code> and <code>cudaMemset()</code> are actually asynchronous and need such explicit synchronization! Use <code>cudaMemcpyAsync()</code> and <code>cudaMemsetAsync()</code> instead.</p>
<p>Calling <a class="el" href="group__API__CUDA__Extensions.html#ga9f70358bd39f2228d7b0558702306d96">starpu_cublas_init()</a> will ensure StarPU to properly call the CUBLAS library functions. Some libraries like Magma may however change the current stream of CUBLAS v1, one then has to call <code>cublasSetKernelStream(</code><a class="el" href="group__API__CUDA__Extensions.html#gad7d80d054bd2b9570e1d7e24442e19c0">starpu_cuda_get_local_stream()</a><code>)</code> at the beginning of the codelet to make sure that CUBLAS is really using the proper stream. When using CUBLAS v2, <a class="el" href="group__API__CUDA__Extensions.html#ga36e0141d9f28894cbb0c3235afc32ed1">starpu_cublas_get_local_handle()</a> can be called to queue CUBLAS kernels with the proper configuration.</p>
<p>Similarly, calling <a class="el" href="group__API__CUDA__Extensions.html#ga60f4393ac61f22cafc9b13386274acba">starpu_cusparse_init()</a> makes StarPU create CUSPARSE handles on each CUDA device, <a class="el" href="group__API__CUDA__Extensions.html#ga91a1f8b244999a0138d41df182b71846">starpu_cusparse_get_local_handle()</a> can then be used to queue CUSPARSE kernels with the proper configuration.</p>
<p>If the kernel can be made to only use this local stream or other self-allocated streams, i.e. the whole kernel submission can be made asynchronous, then one should enable asynchronous execution of the kernel. This means setting the flag <a class="el" href="group__API__Codelet__And__Tasks.html#gac91ae22b428595d3956a1c2225e2621e">STARPU_CUDA_ASYNC</a> in the corresponding field <a class="el" href="group__API__Codelet__And__Tasks.html#aaa458493da38622be2713700f3c96a5d">starpu_codelet::cuda_flags</a>, and dropping the <code>cudaStreamSynchronize()</code> call at the end of the <code>cuda_func</code> function, so that it returns immediately after having queued the kernel to the local stream. That way, StarPU will be able to submit and complete data transfers while kernels are executing, instead of only at each kernel submission. The kernel just has to make sure that StarPU can use the local stream to synchronize with the kernel startup and completion.</p>
<p>Using the flag <a class="el" href="group__API__Codelet__And__Tasks.html#gac91ae22b428595d3956a1c2225e2621e">STARPU_CUDA_ASYNC</a> also permits to enable concurrent kernel execution, on cards which support it (Kepler and later, notably). This is enabled by setting the environment variable <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_NWORKER_PER_CUDA">STARPU_NWORKER_PER_CUDA</a> to the number of kernels to be executed concurrently. This is useful when kernels are small and do not feed the whole GPU with threads to run.</p>
<p>Concerning memory allocation, you should really not use <code>cudaMalloc()/</code> <code>cudaFree()</code> within the kernel, since <code>cudaFree()</code> introduces a awfully lot of synchronizations within CUDA itself. You should instead add a parameter to the codelet with the <a class="el" href="group__API__Data__Management.html#gga1fb3a1ff8622747d653d1b5f41bc41dba5531afb0a53e301d4bff753fed705179">STARPU_SCRATCH</a> mode access. You can then pass to the task a handle registered with the desired size but with the <code>NULL</code> pointer, the handle can even be shared between tasks, StarPU will allocate per-task data on the fly before task execution, and reuse the allocated data between tasks.</p>
<p>See <code>examples/pi/pi_redux.c</code> for an example of use.</p>
<h1><a class="anchor" id="OpenCL-specificOptimizations"></a>
OpenCL-specific Optimizations</h1>
<p>If the kernel can be made to only use the StarPU-provided command queue or other self-allocated queues, i.e. the whole kernel submission can be made asynchronous, then one should enable asynchronous execution of the kernel. This means setting the flag <a class="el" href="group__API__Codelet__And__Tasks.html#ga3c2546614b19e43aad2bed0d935b38b4">STARPU_OPENCL_ASYNC</a> in the corresponding field <a class="el" href="group__API__Codelet__And__Tasks.html#a2de77d2c65169749809c078367905a93">starpu_codelet::opencl_flags</a> and dropping the <code>clFinish()</code> and <a class="el" href="group__API__OpenCL__Extensions.html#gaeaabc8e5d90531a21a8307c06c659984">starpu_opencl_collect_stats()</a> calls at the end of the kernel, so that it returns immediately after having queued the kernel to the provided queue. That way, StarPU will be able to submit and complete data transfers while kernels are executing, instead of only at each kernel submission. The kernel just has to make sure that StarPU can use the command queue it has provided to synchronize with the kernel startup and completion.</p>
<h1><a class="anchor" id="DetectionStuckConditions"></a>
Detecting Stuck Conditions</h1>
<p>It may happen that for some reason, StarPU does not make progress for a long period of time. Reason are sometimes due to contention inside StarPU, but sometimes this is due to external reasons, such as a stuck MPI or CUDA driver.</p>
<p><code>export STARPU_WATCHDOG_TIMEOUT=10000</code> (<a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_WATCHDOG_TIMEOUT">STARPU_WATCHDOG_TIMEOUT</a>)</p>
<p>allows to make StarPU print an error message whenever StarPU does not terminate any task for 10ms, but lets the application continue normally. In addition to that,</p>
<p><code>export STARPU_WATCHDOG_CRASH=1</code> (<a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_WATCHDOG_CRASH">STARPU_WATCHDOG_CRASH</a>)</p>
<p>raises <code>SIGABRT</code> in this condition, thus allowing to catch the situation in <code>gdb</code>.</p>
<p>It can also be useful to type <code>handle SIGABRT nopass</code> in <code>gdb</code> to be able to let the process continue, after inspecting the state of the process.</p>
<h1><a class="anchor" id="HowToLimitMemoryPerNode"></a>
How to Limit Memory Used By StarPU And Cache Buffer Allocations</h1>
<p>By default, StarPU makes sure to use at most 90% of the memory of GPU devices, moving data in and out of the device as appropriate, as well as using prefetch and writeback optimizations.</p>
<p>The environment variables <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_LIMIT_CUDA_MEM">STARPU_LIMIT_CUDA_MEM</a>, <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_LIMIT_CUDA_devid_MEM">STARPU_LIMIT_CUDA_devid_MEM</a>, <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_LIMIT_OPENCL_MEM">STARPU_LIMIT_OPENCL_MEM</a>, and <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_LIMIT_OPENCL_devid_MEM">STARPU_LIMIT_OPENCL_devid_MEM</a> can be used to control how much (in MiB) of the GPU device memory should be used at most by StarPU (the default value is to use 90% of the available memory).</p>
<p>By default, the usage of the main memory is not limited, as the default mechanims do not provide means to evict main memory when it gets too tight. This also means that by default StarPU will not cache buffer allocations in main memory, since it does not know how much of the system memory it can afford.</p>
<p>The environment variable <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_LIMIT_CPU_MEM">STARPU_LIMIT_CPU_MEM</a> can be used to specify how much (in MiB) of the main memory should be used at most by StarPU for buffer allocations. This way, StarPU will be able to cache buffer allocations (which can be a real benefit if a lot of buffers are involved, or if allocation fragmentation can become a problem), and when using <a class="el" href="OutOfCore.html">Out Of Core</a>, StarPU will know when it should evict data out to the disk.</p>
<p>It should be noted that by default only buffer allocations automatically done by StarPU are accounted here, i.e. allocations performed through <a class="el" href="group__API__Data__Interfaces.html#gab91cbc596a65e6a4322b657c79934269">starpu_malloc_on_node()</a> which are used by the data interfaces (matrix, vector, etc.). This does not include allocations performed by the application through e.g. malloc(). It does not include allocations performed through <a class="el" href="group__API__Standard__Memory__Library.html#ga49603eaea3b05e8ced9ba1bd873070c3">starpu_malloc()</a> either, only allocations performed explicitly with the <a class="el" href="group__API__Standard__Memory__Library.html#gaace5eebbb6662fb1be7c79a65464e1cc">STARPU_MALLOC_COUNT</a> flag, i.e. by calling</p>
<div class="fragment"><div class="line"><a class="code" href="group__API__Standard__Memory__Library.html#gaebaa5a1503be11ba7da92f72a8e601b2">starpu_malloc_flags</a>(<a class="code" href="group__API__Standard__Memory__Library.html#gaace5eebbb6662fb1be7c79a65464e1cc">STARPU_MALLOC_COUNT</a>)</div></div><!-- fragment --><p>are taken into account. If the application wants to make StarPU aware of its own allocations, so that StarPU knows precisely how much data is allocated, and thus when to evict allocation caches or data out to the disk, <a class="el" href="group__API__Standard__Memory__Library.html#ga84894d9a6726bca707043f484bd1a8f5">starpu_memory_allocate()</a> can be used to specify an amount of memory to be accounted for. <a class="el" href="group__API__Standard__Memory__Library.html#ga9e545c4701e6db29ab38bd0f7e4a76b5">starpu_memory_deallocate()</a> can be used to account freed memory back. Those can for instance be used by data interfaces with dynamic data buffers: instead of using <a class="el" href="group__API__Data__Interfaces.html#gab91cbc596a65e6a4322b657c79934269">starpu_malloc_on_node()</a>, they would dynamically allocate data with <code>malloc()/<code>realloc()</code>,</code> and notify StarPU of the delta by calling <a class="el" href="group__API__Standard__Memory__Library.html#ga84894d9a6726bca707043f484bd1a8f5">starpu_memory_allocate()</a> and <a class="el" href="group__API__Standard__Memory__Library.html#ga9e545c4701e6db29ab38bd0f7e4a76b5">starpu_memory_deallocate()</a>.</p>
<p><a class="el" href="group__API__Standard__Memory__Library.html#ga552a99a9bb5c02acd10ed744c9c00a9d">starpu_memory_get_total()</a> and <a class="el" href="group__API__Standard__Memory__Library.html#ga13b23ecc431501f8aebcb7b498acd92b">starpu_memory_get_available()</a> can be used to get an estimation of how much memory is available. <a class="el" href="group__API__Standard__Memory__Library.html#ga71ec84f082fd96f53612e684eda0e178">starpu_memory_wait_available()</a> can also be used to block until an amount of memory becomes available, but it may be preferrable to call</p>
<div class="fragment"><div class="line"><a class="code" href="group__API__Standard__Memory__Library.html#ga84894d9a6726bca707043f484bd1a8f5">starpu_memory_allocate</a>(<a class="code" href="group__API__Standard__Memory__Library.html#ga8601b3e35b74e9cbbcefd7a9b9c6d0b8">STARPU_MEMORY_WAIT</a>)</div></div><!-- fragment --><p>to reserve this amount immediately.</p>
<h1><a class="anchor" id="HowToReduceTheMemoryFootprintOfInternalDataStructures"></a>
How To Reduce The Memory Footprint Of Internal Data Structures</h1>
<p>It is possible to reduce the memory footprint of the task and data internal structures of StarPU by describing the shape of your machine and/or your application when calling <code>configure</code>.</p>
<p>To reduce the memory footprint of the data internal structures of StarPU, one can set the <a class="el" href="CompilationConfiguration.html#enable-maxcpus">--enable-maxcpus</a>, <a class="el" href="CompilationConfiguration.html#enable-maxnumanodes">--enable-maxnumanodes</a>, <a class="el" href="CompilationConfiguration.html#enable-maxcudadev">--enable-maxcudadev</a>, <a class="el" href="CompilationConfiguration.html#enable-maxopencldev">--enable-maxopencldev</a> and <a class="el" href="CompilationConfiguration.html#enable-maxnodes">--enable-maxnodes</a> <code>configure</code> parameters to give StarPU the architecture of the machine it will run on, thus tuning the size of the structures to the machine.</p>
<p>To reduce the memory footprint of the task internal structures of StarPU, one can set the <a class="el" href="CompilationConfiguration.html#enable-maxbuffers">--enable-maxbuffers</a> <code>configure</code> parameter to give StarPU the maximum number of buffers that a task can use during an execution. For example, in the Cholesky factorization (dense linear algebra application), the GEMM task uses up to 3 buffers, so it is possible to set the maximum number of task buffers to 3 to run a Cholesky factorization on StarPU.</p>
<p>The size of the various structures of StarPU can be printed by <code>tests/microbenchs/display_structures_size</code>.</p>
<p>It is also often useless to submit *all* the tasks at the same time. Task submission can be blocked when a reasonable given number of tasks have been submitted, by setting the environment variables <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_LIMIT_MIN_SUBMITTED_TASKS">STARPU_LIMIT_MIN_SUBMITTED_TASKS</a> and <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_LIMIT_MAX_SUBMITTED_TASKS">STARPU_LIMIT_MAX_SUBMITTED_TASKS</a>.</p>
<p><code> export STARPU_LIMIT_MAX_SUBMITTED_TASKS=10000 export STARPU_LIMIT_MIN_SUBMITTED_TASKS=9000 </code></p>
<p>will make StarPU block submission when 10000 tasks are submitted, and unblock submission when only 9000 tasks are still submitted, i.e. 1000 tasks have completed among the 10000 which were submitted when submission was blocked. Of course this may reduce parallelism if the threshold is set too low. The precise balance depends on the application task graph.</p>
<p>An idea of how much memory is used for tasks and data handles can be obtained by setting the environment variable <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_MAX_MEMORY_USE">STARPU_MAX_MEMORY_USE</a> to <code>1</code>.</p>
<h1><a class="anchor" id="HowtoReuseMemory"></a>
How To Reuse Memory</h1>
<p>When your application needs to allocate more data than the available amount of memory usable by StarPU (given by <a class="el" href="group__API__Standard__Memory__Library.html#ga13b23ecc431501f8aebcb7b498acd92b">starpu_memory_get_available()</a>), the allocation cache system can reuse data buffers used by previously executed tasks. For this system to work with MPI tasks, you need to submit tasks progressively instead of as soon as possible, because in the case of MPI receives, the allocation cache check for reusing data buffers will be done at submission time, not at execution time.</p>
<p>There is two options to control the task submission flow. The first one is by controlling the number of submitted tasks during the whole execution. This can be done whether by setting the environment variables <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_LIMIT_MAX_SUBMITTED_TASKS">STARPU_LIMIT_MAX_SUBMITTED_TASKS</a> and <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_LIMIT_MIN_SUBMITTED_TASKS">STARPU_LIMIT_MIN_SUBMITTED_TASKS</a> to tell StarPU when to stop submitting tasks and when to wake up and submit tasks again, or by explicitely calling <a class="el" href="group__API__Codelet__And__Tasks.html#ga724cda8b0ffeaa7532a5e573b86bc90b">starpu_task_wait_for_n_submitted()</a> in your application code for finest grain control (for example, between two iterations of a submission loop).</p>
<p>The second option is to control the memory size of the allocation cache. This can be done in the application by using jointly <a class="el" href="group__API__Standard__Memory__Library.html#ga13b23ecc431501f8aebcb7b498acd92b">starpu_memory_get_available()</a> and <a class="el" href="group__API__Standard__Memory__Library.html#ga71ec84f082fd96f53612e684eda0e178">starpu_memory_wait_available()</a> to submit tasks only when there is enough memory space to allocate the data needed by the task, i.e when enough data are available for reuse in the allocation cache.</p>
<h1><a class="anchor" id="PerformanceModelCalibration"></a>
Performance Model Calibration</h1>
<p>Most schedulers are based on an estimation of codelet duration on each kind of processing unit. For this to be possible, the application programmer needs to configure a performance model for the codelets of the application (see <a class="el" href="OnlinePerformanceTools.html#PerformanceModelExample">Performance Model Example</a> for instance). History-based performance models use on-line calibration. StarPU will automatically calibrate codelets which have never been calibrated yet, and save the result in <code>$STARPU_HOME/.starpu/sampling/codelets</code>. The models are indexed by machine name.</p>
<p>By default, StarPU stores separate performance models according to the hostname of the system. To avoid having to calibrate performance models for each node of a homogeneous cluster for instance, the model can be shared by using <code>export STARPU_HOSTNAME=some_global_name</code> (<a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_HOSTNAME">STARPU_HOSTNAME</a>), where <code>some_global_name</code> is the name of the cluster for instance, which thus overrides the hostname of the system.</p>
<p>By default, StarPU stores separate performance models for each GPU. To avoid having to calibrate performance models for each GPU of a homogeneous set of GPU devices for instance, the model can be shared by setting <code>export STARPU_PERF_MODEL_HOMOGENEOUS_CUDA=1</code> (<a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_PERF_MODEL_HOMOGENEOUS_CUDA">STARPU_PERF_MODEL_HOMOGENEOUS_CUDA</a>), <code>export STARPU_PERF_MODEL_HOMOGENEOUS_OPENCL=1</code> (<a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_PERF_MODEL_HOMOGENEOUS_OPENCL">STARPU_PERF_MODEL_HOMOGENEOUS_OPENCL</a>), <code>export STARPU_PERF_MODEL_HOMOGENEOUS_MIC=1</code> (<a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_PERF_MODEL_HOMOGENEOUS_MIC">STARPU_PERF_MODEL_HOMOGENEOUS_MIC</a>), <code>export STARPU_PERF_MODEL_HOMOGENEOUS_MPI_MS=1</code> (<a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_PERF_MODEL_HOMOGENEOUS_MPI_MS">STARPU_PERF_MODEL_HOMOGENEOUS_MPI_MS</a>) depending on your GPU device type.</p>
<p>To force continuing calibration, use <code>export STARPU_CALIBRATE=1</code> (<a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_CALIBRATE">STARPU_CALIBRATE</a>). This may be necessary if your application has not-so-stable performance. StarPU will force calibration (and thus ignore the current result) until 10 (<code>_STARPU_CALIBRATION_MINIMUM</code>) measurements have been made on each architecture, to avoid bad scheduling decisions just because the first measurements were not so good.</p>
<p>Note that StarPU will not record the very first measurement for a given codelet and a given size, because it would most often be hit by computation library loading or initialization. StarPU will also throw measurements away if it notices that after computing an average execution time, it notices that most subsequent tasks have an execution time largely outside the computed average ("Too big deviation for model..." warning messages). By looking at the details of the message and their reported measurements, it can highlight that your computation library really has non-stable measurements, which is probably an indication of an issue in the computation library, or the execution environment (e.g. rogue daemons).</p>
<p>Details on the current performance model status can be obtained with the tool <code>starpu_perfmodel_display</code>: the option <code>-l</code> lists the available performance models, and the option <code>-s</code> allows to choose the performance model to be displayed. The result looks like:</p>
<pre class="fragment">$ starpu_perfmodel_display -s starpu_slu_lu_model_11
performance model for cpu_impl_0
# hash    size     flops         mean          dev           n
914f3bef  1048576  0.000000e+00  2.503577e+04  1.982465e+02  8
3e921964  65536    0.000000e+00  5.527003e+02  1.848114e+01  7
e5a07e31  4096     0.000000e+00  1.717457e+01  5.190038e+00  14
...
</pre><p>which shows that for the LU 11 kernel with a 1MiB matrix, the average execution time on CPUs was about 25ms, with a 0.2ms standard deviation, over 8 samples. It is a good idea to check this before doing actual performance measurements.</p>
<p>A graph can be drawn by using the tool <code>starpu_perfmodel_plot</code>:</p>
<pre class="fragment">$ starpu_perfmodel_plot -s starpu_slu_lu_model_11
4096 16384 65536 262144 1048576 4194304
$ gnuplot starpu_starpu_slu_lu_model_11.gp
$ gv starpu_starpu_slu_lu_model_11.eps
</pre><div class="image">
<img src="starpu_starpu_slu_lu_model_11.png" alt="starpu_starpu_slu_lu_model_11.png"/>
</div>
 <p>If a kernel source code was modified (e.g. performance improvement), the calibration information is stale and should be dropped, to re-calibrate from start. This can be done by using <code>export STARPU_CALIBRATE=2</code> (<a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_CALIBRATE">STARPU_CALIBRATE</a>).</p>
<p>Note: history-based performance models get calibrated only if a performance-model-based scheduler is chosen.</p>
<p>The history-based performance models can also be explicitly filled by the application without execution, if e.g. the application already has a series of measurements. This can be done by using <a class="el" href="group__API__Performance__Model.html#gaecb9341bff471557abbb63a966449481">starpu_perfmodel_update_history()</a>, for instance:</p>
<div class="fragment"><div class="line"><span class="keyword">static</span> <span class="keyword">struct </span><a class="code" href="group__API__Performance__Model.html#structstarpu__perfmodel">starpu_perfmodel</a> perf_model =</div><div class="line">{</div><div class="line">    .<a class="code" href="group__API__Performance__Model.html#afe2d561aaba7bf1ad1cf03974ee8c53c">type</a> = <a class="code" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6ab1ea457716c143f155593a2112e38f35">STARPU_HISTORY_BASED</a>,</div><div class="line">    .symbol = <span class="stringliteral">&quot;my_perfmodel&quot;</span>,</div><div class="line">};</div><div class="line"></div><div class="line"><span class="keyword">struct </span><a class="code" href="group__API__Codelet__And__Tasks.html#structstarpu__codelet">starpu_codelet</a> cl =</div><div class="line">{</div><div class="line">    .<a class="code" href="group__API__Codelet__And__Tasks.html#aa6a8436117176270c5372d4dfb006a1f">cuda_funcs</a> = { cuda_func1, cuda_func2 },</div><div class="line">    .nbuffers = 1,</div><div class="line">    .modes = {<a class="code" href="group__API__Data__Management.html#gga1fb3a1ff8622747d653d1b5f41bc41dba628e5483f4cb6e44779aea39300dafed">STARPU_W</a>},</div><div class="line">    .model = &amp;perf_model</div><div class="line">};</div><div class="line"></div><div class="line"><span class="keywordtype">void</span> feed(<span class="keywordtype">void</span>)</div><div class="line">{</div><div class="line">    <span class="keyword">struct </span>my_measure *measure;</div><div class="line">    <span class="keyword">struct </span><a class="code" href="group__API__Codelet__And__Tasks.html#structstarpu__task">starpu_task</a> task;</div><div class="line">    <a class="code" href="group__API__Codelet__And__Tasks.html#gadf8b76ef62ba0e68684e07ebf1db1731">starpu_task_init</a>(&amp;task);</div><div class="line"></div><div class="line">    task.<a class="code" href="group__API__Codelet__And__Tasks.html#ac0e8ab897e436b244f13ec17b1191062">cl</a> = &amp;<a class="code" href="group__API__Codelet__And__Tasks.html#ac0e8ab897e436b244f13ec17b1191062">cl</a>;</div><div class="line"></div><div class="line">    <span class="keywordflow">for</span> (measure = &amp;measures[0]; measure &lt; measures[last]; measure++)</div><div class="line">    {</div><div class="line">        <a class="code" href="group__API__Data__Management.html#gad6bed33cdb76ef504efcdf05e5788076">starpu_data_handle_t</a> handle;</div><div class="line">        <a class="code" href="group__API__Data__Interfaces.html#ga4248716bc322e1628b86365d7b9a8822">starpu_vector_data_register</a>(&amp;handle, -1, 0, measure-&gt;size, <span class="keyword">sizeof</span>(<span class="keywordtype">float</span>));</div><div class="line">        task.<a class="code" href="group__API__Codelet__And__Tasks.html#af3ce0252f1ac2238325033386a726df3">handles</a>[0] = handle;</div><div class="line">        <a class="code" href="group__API__Performance__Model.html#gaecb9341bff471557abbb63a966449481">starpu_perfmodel_update_history</a>(&amp;perf_model, &amp;task, STARPU_CUDA_DEFAULT + measure-&gt;cudadev, 0, measure-&gt;implementation, measure-&gt;time);</div><div class="line">        <a class="code" href="group__API__Codelet__And__Tasks.html#gaecb3efa04cb10b049b10c6166dd9c30c">starpu_task_clean</a>(&amp;task);</div><div class="line">        <a class="code" href="group__API__Data__Management.html#ga586146498466b60d6b81145dfaeb8948">starpu_data_unregister</a>(handle);</div><div class="line">    }</div><div class="line">}</div></div><!-- fragment --><p>Measurement has to be provided in milliseconds for the completion time models, and in Joules for the energy consumption models.</p>
<h1><a class="anchor" id="Profiling"></a>
Profiling</h1>
<p>A quick view of how many tasks each worker has executed can be obtained by setting <code>export STARPU_WORKER_STATS=1</code> (<a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_WORKER_STATS">STARPU_WORKER_STATS</a>). This is a convenient way to check that execution did happen on accelerators, without penalizing performance with the profiling overhead. <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_WORKER_STATS_FILE">STARPU_WORKER_STATS_FILE</a> can be defined to specify a filename in which to display statistics, by default statistics are printed on the standard error stream.</p>
<p>A quick view of how much data transfers have been issued can be obtained by setting <code>export STARPU_BUS_STATS=1</code> (<a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_BUS_STATS">STARPU_BUS_STATS</a>). <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_BUS_STATS_FILE">STARPU_BUS_STATS_FILE</a> can be defined to specify a filename in which to display statistics, by default statistics are printed on the standard error stream.</p>
<p>More detailed profiling information can be enabled by using <code>export STARPU_PROFILING=1</code> (<a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_PROFILING">STARPU_PROFILING</a>) or by calling <a class="el" href="group__API__Profiling.html#gabeb22bbe8062a45507cfc6273aae51ae">starpu_profiling_status_set()</a> from the source code. Statistics on the execution can then be obtained by using <code>export STARPU_BUS_STATS=1</code> and <code>export STARPU_WORKER_STATS=1</code> . More details on performance feedback are provided in the next chapter.</p>
<h1><a class="anchor" id="OverheadProfiling"></a>
Overhead Profiling</h1>
<p><a class="el" href="OfflinePerformanceTools.html">Offline Performance Tools</a> can already provide an idea of to what extent and which part of StarPU brings an overhead on the execution time. To get a more precise analysis of which parts of StarPU bring the most overhead, <code>gprof</code> can be used.</p>
<p>First, recompile and reinstall StarPU with <code>gprof</code> support:</p>
<div class="fragment"><div class="line">../configure --enable-perf-debug --disable-shared --disable-build-tests --disable-build-examples</div></div><!-- fragment --><p>Make sure not to leave a dynamic version of StarPU in the target path: remove any remaining <code>libstarpu-*.so</code></p>
<p>Then relink your application with the static StarPU library, make sure that running <code>ldd</code> on your application does not mention any <code>libstarpu</code> (i.e. it's really statically-linked).</p>
<div class="fragment"><div class="line">gcc test.c -o test $(pkg-config --cflags starpu-1.3) $(pkg-config --libs starpu-1.3)</div></div><!-- fragment --><p>Now you can run your application, this will create a file <code>gmon.out</code> in the current directory, it can be processed by running <code>gprof</code> on your application:</p>
<div class="fragment"><div class="line">gprof ./test</div></div><!-- fragment --><p>This will dump an analysis of the time spent in StarPU functions. </p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Fri Oct 22 2021 15:02:13 for StarPU Handbook by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
