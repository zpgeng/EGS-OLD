<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>StarPU Handbook: Frequently Asked Questions</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">StarPU Handbook
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('FrequentlyAskedQuestions.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Frequently Asked Questions </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="HowToInitializeAComputationLibraryOnceForEachWorker"></a>
How To Initialize A Computation Library Once For Each Worker?</h1>
<p>Some libraries need to be initialized once for each concurrent instance that may run on the machine. For instance, a C++ computation class which is not thread-safe by itself, but for which several instanciated objects of that class can be used concurrently. This can be used in StarPU by initializing one such object per worker. For instance, the <code>libstarpufft</code> example does the following to be able to use FFTW on CPUs.</p>
<p>Some global array stores the instanciated objects:</p>
<div class="fragment"><div class="line">fftw_plan plan_cpu[<a class="code" href="group__API__Workers__Properties.html#gad7c443d1341e4976d63fb5d77e74bf09">STARPU_NMAXWORKERS</a>];</div></div><!-- fragment --><p>At initialisation time of libstarpu, the objects are initialized:</p>
<div class="fragment"><div class="line"><span class="keywordtype">int</span> workerid;</div><div class="line"><span class="keywordflow">for</span> (workerid = 0; workerid &lt; <a class="code" href="group__API__Workers__Properties.html#ga6312aa4b12ce7e06fe391bcafda6796a">starpu_worker_get_count</a>(); workerid++)</div><div class="line">{</div><div class="line">    <span class="keywordflow">switch</span> (<a class="code" href="group__API__Workers__Properties.html#ga4998e4e1dfa0d121059c60f790496a03">starpu_worker_get_type</a>(workerid))</div><div class="line">    {</div><div class="line">        <span class="keywordflow">case</span> <a class="code" href="group__API__Workers__Properties.html#gga173d616aefe98c33a47a847fd2fca37da7fa269b896814504abcf227388233d1f">STARPU_CPU_WORKER</a>:</div><div class="line">            plan_cpu[workerid] = fftw_plan(...);</div><div class="line">            <span class="keywordflow">break</span>;</div><div class="line">    }</div><div class="line">}</div></div><!-- fragment --><p>And in the codelet body, they are used:</p>
<div class="fragment"><div class="line"><span class="keyword">static</span> <span class="keywordtype">void</span> fft(<span class="keywordtype">void</span> *descr[], <span class="keywordtype">void</span> *_args)</div><div class="line">{</div><div class="line">    <span class="keywordtype">int</span> workerid = <a class="code" href="group__API__Workers__Properties.html#gac6d06f4e22b63bf50bc8e836cf16f81f">starpu_worker_get_id</a>();</div><div class="line">    fftw_plan plan = plan_cpu[workerid];</div><div class="line">    ...</div><div class="line"></div><div class="line">    fftw_execute(plan, ...);</div><div class="line">}</div></div><!-- fragment --><p>This however is not sufficient for FFT on CUDA: initialization has to be done from the workers themselves. This can be done thanks to <a class="el" href="group__API__Miscellaneous__Helpers.html#ga7a97b0699b97b30b4d408c660be46102">starpu_execute_on_each_worker()</a>. For instance <code>libstarpufft</code> does the following.</p>
<div class="fragment"><div class="line"><span class="keyword">static</span> <span class="keywordtype">void</span> fft_plan_gpu(<span class="keywordtype">void</span> *args)</div><div class="line">{</div><div class="line">    plan plan = args;</div><div class="line">    <span class="keywordtype">int</span> n2 = plan-&gt;n2[0];</div><div class="line">    <span class="keywordtype">int</span> workerid = <a class="code" href="group__API__Workers__Properties.html#gac6d06f4e22b63bf50bc8e836cf16f81f">starpu_worker_get_id</a>();</div><div class="line"></div><div class="line">    cufftPlan1d(&amp;plan-&gt;plans[workerid].plan_cuda, n, _CUFFT_C2C, 1);</div><div class="line">    cufftSetStream(plan-&gt;plans[workerid].plan_cuda, starpu_cuda_get_local_stream());</div><div class="line">}</div><div class="line"><span class="keywordtype">void</span> starpufft_plan(<span class="keywordtype">void</span>)</div><div class="line">{</div><div class="line">    <a class="code" href="group__API__Miscellaneous__Helpers.html#ga7a97b0699b97b30b4d408c660be46102">starpu_execute_on_each_worker</a>(fft_plan_gpu, plan, <a class="code" href="group__API__Codelet__And__Tasks.html#ga43c37484ac60c15cd6f45ab25c277213">STARPU_CUDA</a>);</div><div class="line">}</div></div><!-- fragment --><h1><a class="anchor" id="UsingTheDriverAPI"></a>
Using The Driver API</h1>
<p><a class="el" href="group__API__Running__Drivers.html">Running Drivers</a></p>
<div class="fragment"><div class="line"><span class="keywordtype">int</span> ret;</div><div class="line"><span class="keyword">struct </span><a class="code" href="group__API__Running__Drivers.html#structstarpu__driver">starpu_driver</a> =</div><div class="line">{</div><div class="line">    .<a class="code" href="group__API__Running__Drivers.html#a50af396b52e8c54e4e3b23803105fc0e">type</a> = <a class="code" href="group__API__Workers__Properties.html#gga173d616aefe98c33a47a847fd2fca37da26ced4e9dfc43343f0b442bb465218a9">STARPU_CUDA_WORKER</a>,</div><div class="line">    .id.cuda_id = 0</div><div class="line">};</div><div class="line">ret = <a class="code" href="group__API__Running__Drivers.html#gab274599ec82fe38cb41267b8a1384995">starpu_driver_init</a>(&amp;d);</div><div class="line"><span class="keywordflow">if</span> (ret != 0)</div><div class="line">    error();</div><div class="line"><span class="keywordflow">while</span> (some_condition)</div><div class="line">{</div><div class="line">    ret = <a class="code" href="group__API__Running__Drivers.html#gad6d01b57f2f84df90f554ea205dcf90d">starpu_driver_run_once</a>(&amp;d);</div><div class="line">    <span class="keywordflow">if</span> (ret != 0)</div><div class="line">        error();</div><div class="line">}</div><div class="line">ret = <a class="code" href="group__API__Running__Drivers.html#gac8f8848b64980676190d77d265fda841">starpu_driver_deinit</a>(&amp;d);</div><div class="line"><span class="keywordflow">if</span> (ret != 0)</div><div class="line">    error();</div></div><!-- fragment --><p>To add a new kind of device to the structure <a class="el" href="group__API__Running__Drivers.html#structstarpu__driver">starpu_driver</a>, one needs to: </p><ol>
<li>
Add a member to the union <a class="el" href="group__API__Running__Drivers.html#aef0ee22d9ef7d9f64e047f5a2014fc6d">starpu_driver::id</a>  </li>
<li>
Modify the internal function <code>_starpu_launch_drivers()</code> to make sure the driver is not always launched.  </li>
<li>
Modify the function <a class="el" href="group__API__Running__Drivers.html#ga68b320765b17e5e4a256f156c9932e69">starpu_driver_run()</a> so that it can handle another kind of architecture.  </li>
<li>
Write the new function <code>_starpu_run_foobar()</code> in the corresponding driver.  </li>
</ol>
<h1><a class="anchor" id="On-GPURendering"></a>
On-GPU Rendering</h1>
<p>Graphical-oriented applications need to draw the result of their computations, typically on the very GPU where these happened. Technologies such as OpenGL/CUDA interoperability permit to let CUDA directly work on the OpenGL buffers, making them thus immediately ready for drawing, by mapping OpenGL buffer, textures or renderbuffer objects into CUDA. CUDA however imposes some technical constraints: peer memcpy has to be disabled, and the thread that runs OpenGL has to be the one that runs CUDA computations for that GPU.</p>
<p>To achieve this with StarPU, pass the option <a class="el" href="CompilationConfiguration.html#disable-cuda-memcpy-peer">--disable-cuda-memcpy-peer</a> to <code>configure</code> (TODO: make it dynamic), OpenGL/GLUT has to be initialized first, and the interoperability mode has to be enabled by using the field <a class="el" href="group__API__Initialization__and__Termination.html#adeb1e95a62549f3ef436bbf13cf30e0a">starpu_conf::cuda_opengl_interoperability</a>, and the driver loop has to be run by the application, by using the field <a class="el" href="group__API__Initialization__and__Termination.html#aff1ae12be0c8b2366e8ecd0d980af806">starpu_conf::not_launched_drivers</a> to prevent StarPU from running it in a separate thread, and by using <a class="el" href="group__API__Running__Drivers.html#ga68b320765b17e5e4a256f156c9932e69">starpu_driver_run()</a> to run the loop. The examples <code>gl_interop</code> and <code>gl_interop_idle</code> show how it articulates in a simple case, where rendering is done in task callbacks. The former uses <code>glutMainLoopEvent</code> to make GLUT progress from the StarPU driver loop, while the latter uses <code>glutIdleFunc</code> to make StarPU progress from the GLUT main loop.</p>
<p>Then, to use an OpenGL buffer as a CUDA data, StarPU simply needs to be given the CUDA pointer at registration, for instance:</p>
<div class="fragment"><div class="line"><span class="comment">/* Get the CUDA worker id */</span></div><div class="line"><span class="keywordflow">for</span> (workerid = 0; workerid &lt; <a class="code" href="group__API__Workers__Properties.html#ga6312aa4b12ce7e06fe391bcafda6796a">starpu_worker_get_count</a>(); workerid++)</div><div class="line">        <span class="keywordflow">if</span> (<a class="code" href="group__API__Workers__Properties.html#ga4998e4e1dfa0d121059c60f790496a03">starpu_worker_get_type</a>(workerid) == <a class="code" href="group__API__Workers__Properties.html#gga173d616aefe98c33a47a847fd2fca37da26ced4e9dfc43343f0b442bb465218a9">STARPU_CUDA_WORKER</a>)</div><div class="line">                <span class="keywordflow">break</span>;</div><div class="line"></div><div class="line"><span class="comment">/* Build a CUDA pointer pointing at the OpenGL buffer */</span></div><div class="line">cudaGraphicsResourceGetMappedPointer((<span class="keywordtype">void</span>**)&amp;output, &amp;num_bytes, resource);</div><div class="line"></div><div class="line"><span class="comment">/* And register it to StarPU */</span></div><div class="line"><a class="code" href="group__API__Data__Interfaces.html#ga4248716bc322e1628b86365d7b9a8822">starpu_vector_data_register</a>(&amp;handle, <a class="code" href="group__API__Workers__Properties.html#ga7de6654141ce89ea83c3aba60486396e">starpu_worker_get_memory_node</a>(workerid), output, num_bytes / <span class="keyword">sizeof</span>(float4), <span class="keyword">sizeof</span>(float4));</div><div class="line"></div><div class="line"><span class="comment">/* The handle can now be used as usual */</span></div><div class="line"><a class="code" href="group__API__Insert__Task.html#gad79a50a21fe717126659b2998209c1c6">starpu_task_insert</a>(&amp;cl, STARPU_RW, handle, 0);</div><div class="line"></div><div class="line"><span class="comment">/* ... */</span></div><div class="line"></div><div class="line"><span class="comment">/* This gets back data into the OpenGL buffer */</span></div><div class="line"><a class="code" href="group__API__Data__Management.html#ga586146498466b60d6b81145dfaeb8948">starpu_data_unregister</a>(handle);</div></div><!-- fragment --><p>and display it e.g. in the callback function.</p>
<h1><a class="anchor" id="UsingStarPUWithMKL"></a>
Using StarPU With MKL 11 (Intel Composer XE 2013)</h1>
<p>Some users had issues with MKL 11 and StarPU (versions 1.1rc1 and 1.0.5) on Linux with MKL, using 1 thread for MKL and doing all the parallelism using StarPU (no multithreaded tasks), setting the environment variable <code>MKL_NUM_THREADS</code> to <code>1</code>, and using the threaded MKL library, with <code>iomp5</code>.</p>
<p>Using this configuration, StarPU only uses 1 core, no matter the value of <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_NCPU">STARPU_NCPU</a>. The problem is actually a thread pinning issue with MKL.</p>
<p>The solution is to set the environment variable KMP_AFFINITY to <code>disabled</code> (<a href="http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011Update/compiler_c/optaps/common/optaps_openmp_thread_affinity.htm">http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011Update/compiler_c/optaps/common/optaps_openmp_thread_affinity.htm</a>).</p>
<h1><a class="anchor" id="ThreadBindingOnNetBSD"></a>
Thread Binding on NetBSD</h1>
<p>When using StarPU on a NetBSD machine, if the topology discovery library <code>hwloc</code> is used, thread binding will fail. To prevent the problem, you should at least use the version 1.7 of <code>hwloc</code>, and also issue the following call:</p>
<pre class="fragment">$ sysctl -w security.models.extensions.user_set_cpu_affinity=1
</pre><p>Or add the following line in the file <code>/etc/sysctl.conf</code></p>
<pre class="fragment">security.models.extensions.user_set_cpu_affinity=1
</pre><h1><a class="anchor" id="StarPUEatsCPUs"></a>
StarPU permanently eats 100% of all CPUs</h1>
<p>Yes, this is on purpose.</p>
<p>By default, StarPU uses active polling on task queues, so as to minimize wake-up latency for better overall performance.</p>
<p>If eating CPU time is a problem (e.g. application running on a desktop), pass option <a class="el" href="CompilationConfiguration.html#enable-blocking-drivers">--enable-blocking-drivers</a> to <code>configure</code>. This will add some overhead when putting CPU workers to sleep or waking them, but avoid eating 100% CPU permanently.</p>
<h1><a class="anchor" id="PauseResume"></a>
Interleaving StarPU and non-StarPU code</h1>
<p>If your application only partially uses StarPU, and you do not want to call <a class="el" href="group__API__Initialization__and__Termination.html#ga9ce171bcbbee2edd169ba2649e6e75e3">starpu_init()</a> / <a class="el" href="group__API__Initialization__and__Termination.html#ga48edf5e30e71fbb71923e3867ad16c0a">starpu_shutdown()</a> at the beginning/end of each section, StarPU workers will poll for work between the sections. To avoid this behavior, you can "pause" StarPU with the <a class="el" href="group__API__Initialization__and__Termination.html#ga887fbd250ba7843400b4438d617213d6">starpu_pause()</a> function. This will prevent the StarPU workers from accepting new work (tasks that are already in progress will not be frozen), and stop them from polling for more work.</p>
<p>Note that this does not prevent you from submitting new tasks, but they won't execute until <a class="el" href="group__API__Initialization__and__Termination.html#gad1aff0c793b50e50f995232c110bde66">starpu_resume()</a> is called. Also note that StarPU must not be paused when you call <a class="el" href="group__API__Initialization__and__Termination.html#ga48edf5e30e71fbb71923e3867ad16c0a">starpu_shutdown()</a>, and that this function pair works in a push/pull manner, i.e you need to match the number of calls to these functions to clear their effect.</p>
<p>One way to use these functions could be: </p><div class="fragment"><div class="line"><a class="code" href="group__API__Initialization__and__Termination.html#ga9ce171bcbbee2edd169ba2649e6e75e3">starpu_init</a>(NULL);</div><div class="line"><a class="code" href="group__API__Initialization__and__Termination.html#ga887fbd250ba7843400b4438d617213d6">starpu_pause</a>(); <span class="comment">// To submit all the tasks without a single one executing</span></div><div class="line">submit_some_tasks();</div><div class="line"><a class="code" href="group__API__Initialization__and__Termination.html#gad1aff0c793b50e50f995232c110bde66">starpu_resume</a>(); <span class="comment">// The tasks start executing</span></div><div class="line"></div><div class="line"></div><div class="line"><a class="code" href="group__API__Codelet__And__Tasks.html#gad0baa8dbfd13e5a7bc3651bcd76022aa">starpu_task_wait_for_all</a>();</div><div class="line"><a class="code" href="group__API__Initialization__and__Termination.html#ga887fbd250ba7843400b4438d617213d6">starpu_pause</a>(); <span class="comment">// Stop the workers from polling</span></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><a class="code" href="group__API__Initialization__and__Termination.html#gad1aff0c793b50e50f995232c110bde66">starpu_resume</a>();</div><div class="line"></div><div class="line"><a class="code" href="group__API__Initialization__and__Termination.html#ga48edf5e30e71fbb71923e3867ad16c0a">starpu_shutdown</a>();</div></div><!-- fragment --><h1><a class="anchor" id="GPUEatingCores"></a>
When running with CUDA or OpenCL devices, I am seeing less CPU cores</h1>
<p>Yes, this is on purpose.</p>
<p>Since GPU devices are way faster than CPUs, StarPU needs to react quickly when a task is finished, to feed the GPU with another task (StarPU actually submits a couple of tasks in advance so as to pipeline this, but filling the pipeline still has to be happening often enough), and thus it has to dedicate threads for this, and this is a very CPU-consuming duty. StarPU thus dedicates one CPU core for driving each GPU by default.</p>
<p>Such dedication is also useful when a codelet is hybrid, i.e. while kernels are running on the GPU, the codelet can run some computation, which thus be run by the CPU core instead of driving the GPU.</p>
<p>One can choose to dedicate only one thread for all the CUDA devices by setting the <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_CUDA_THREAD_PER_DEV">STARPU_CUDA_THREAD_PER_DEV</a> environment variable to <code>1</code>. The application however should use <a class="el" href="group__API__Codelet__And__Tasks.html#gac91ae22b428595d3956a1c2225e2621e">STARPU_CUDA_ASYNC</a> on its CUDA codelets (asynchronous execution), otherwise the execution of a synchronous CUDA codelet will monopolize the thread, and other CUDA devices will thus starve while it is executing.</p>
<h1><a class="anchor" id="CUDADrivers"></a>
StarPU does not see my CUDA device</h1>
<p>First make sure that CUDA is properly running outside StarPU: build and run the following program with <code>-lcudart</code> :</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;stdio.h&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;cuda.h&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;cuda_runtime.h&gt;</span></div><div class="line"></div><div class="line"><span class="keywordtype">int</span> main(<span class="keywordtype">void</span>)</div><div class="line">{</div><div class="line">        <span class="keywordtype">int</span> n, i, version;</div><div class="line">        cudaError_t err;</div><div class="line"></div><div class="line">        err = cudaGetDeviceCount(&amp;n);</div><div class="line">        <span class="keywordflow">if</span> (err)</div><div class="line">        {</div><div class="line">                fprintf(stderr,<span class="stringliteral">&quot;cuda error %d\n&quot;</span>, err);</div><div class="line">                exit(1);</div><div class="line">        }</div><div class="line">        cudaDriverGetVersion(&amp;version);</div><div class="line">        printf(<span class="stringliteral">&quot;driver version %d\n&quot;</span>, version);</div><div class="line">        cudaRuntimeGetVersion(&amp;version);</div><div class="line">        printf(<span class="stringliteral">&quot;runtime version %d\n&quot;</span>, version);</div><div class="line">        printf(<span class="stringliteral">&quot;\n&quot;</span>);</div><div class="line"></div><div class="line">        <span class="keywordflow">for</span> (i = 0; i &lt; n; i++)</div><div class="line">        {</div><div class="line">                <span class="keyword">struct </span>cudaDeviceProp props;</div><div class="line">                printf(<span class="stringliteral">&quot;CUDA%d\n&quot;</span>, i);</div><div class="line">                err = cudaGetDeviceProperties(&amp;props, i);</div><div class="line">                <span class="keywordflow">if</span> (err)</div><div class="line">                {</div><div class="line">                        fprintf(stderr,<span class="stringliteral">&quot;cuda error %d\n&quot;</span>, err);</div><div class="line">                        <span class="keywordflow">continue</span>;</div><div class="line">                }</div><div class="line">                printf(<span class="stringliteral">&quot;%s\n&quot;</span>, props.name);</div><div class="line">                printf(<span class="stringliteral">&quot;%0.3f GB\n&quot;</span>, (<span class="keywordtype">float</span>) props.totalGlobalMem / (1&lt;&lt;30));</div><div class="line">                printf(<span class="stringliteral">&quot;%u MP\n&quot;</span>, props.multiProcessorCount);</div><div class="line">                printf(<span class="stringliteral">&quot;\n&quot;</span>);</div><div class="line">        }</div><div class="line">        <span class="keywordflow">return</span> 0;</div><div class="line">}</div></div><!-- fragment --><p>If that program does not find your device, the problem is not at the StarPU level, but the CUDA drivers, check the documentation of your CUDA setup.</p>
<h1><a class="anchor" id="OpenCLDrivers"></a>
StarPU does not see my OpenCL device</h1>
<p>First make sure that OpenCL is properly running outside StarPU: build and run the following program with <code>-lOpenCL</code> :</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;CL/cl.h&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;stdio.h&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;assert.h&gt;</span></div><div class="line"></div><div class="line"><span class="keywordtype">int</span> main(<span class="keywordtype">void</span>)</div><div class="line">{</div><div class="line">    cl_device_id did[16];</div><div class="line">    cl_int err;</div><div class="line">    cl_platform_id pid, pids[16];</div><div class="line">    cl_uint nbplat, nb;</div><div class="line">    <span class="keywordtype">char</span> buf[128];</div><div class="line">    <span class="keywordtype">size_t</span> size;</div><div class="line">    <span class="keywordtype">int</span> i, j;</div><div class="line"></div><div class="line">    err = clGetPlatformIDs(<span class="keyword">sizeof</span>(pids)/<span class="keyword">sizeof</span>(pids[0]), pids, &amp;nbplat);</div><div class="line">    assert(err == CL_SUCCESS);</div><div class="line">    printf(<span class="stringliteral">&quot;%u platforms\n&quot;</span>, nbplat);</div><div class="line">    <span class="keywordflow">for</span> (j = 0; j &lt; nbplat; j++)</div><div class="line">    {</div><div class="line">        pid = pids[j];</div><div class="line">        printf(<span class="stringliteral">&quot;    platform %d\n&quot;</span>, j);</div><div class="line">        err = clGetPlatformInfo(pid, CL_PLATFORM_VERSION, <span class="keyword">sizeof</span>(buf)-1, buf, &amp;size);</div><div class="line">        assert(err == CL_SUCCESS);</div><div class="line">        buf[size] = 0;</div><div class="line">        printf(<span class="stringliteral">&quot;        platform version %s\n&quot;</span>, buf);</div><div class="line"></div><div class="line">        err = clGetDeviceIDs(pid, CL_DEVICE_TYPE_ALL, <span class="keyword">sizeof</span>(did)/<span class="keyword">sizeof</span>(did[0]), did, &amp;nb);</div><div class="line">        assert(err == CL_SUCCESS);</div><div class="line">        printf(<span class="stringliteral">&quot;%d devices\n&quot;</span>, nb);</div><div class="line">        <span class="keywordflow">for</span> (i = 0; i &lt; nb; i++)</div><div class="line">        {</div><div class="line">            err = clGetDeviceInfo(did[i], CL_DEVICE_VERSION, <span class="keyword">sizeof</span>(buf)-1, buf, &amp;size);</div><div class="line">            buf[size] = 0;</div><div class="line">            printf(<span class="stringliteral">&quot;    device %d version %s\n&quot;</span>, i, buf);</div><div class="line">        }</div><div class="line">    }</div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div></div><!-- fragment --><p>If that program does not find your device, the problem is not at the StarPU level, but the OpenCL drivers, check the documentation of your OpenCL implementation.</p>
<h1><a class="anchor" id="IncorrectPerformanceModelFile"></a>
I keep getting a "Incorrect performance model file" error</h1>
<p>The performance model file, used by StarPU to record the performance of codelets, seem to have been corrupted. Perhaps a previous run of StarPU stopped abruptly, and thus could not save it properly. You can have a look at the file if you can fix it, but the simplest way is to just remove the file and run again, StarPU will just have to re-perform calibration for the corresponding codelet. </p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Fri Oct 22 2021 15:02:16 for StarPU Handbook by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
