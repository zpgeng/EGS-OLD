<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>StarPU Handbook: Online Performance Tools</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">StarPU Handbook
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('OnlinePerformanceTools.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Online Performance Tools </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="On-linePerformanceFeedback"></a>
On-line Performance Feedback</h1>
<h2><a class="anchor" id="EnablingOn-linePerformanceMonitoring"></a>
Enabling On-line Performance Monitoring</h2>
<p>In order to enable online performance monitoring, the application can call <a class="el" href="group__API__Profiling.html#gabeb22bbe8062a45507cfc6273aae51ae">starpu_profiling_status_set()</a> with the parameter <a class="el" href="group__API__Profiling.html#gad04bdc4bfc1e053441ba5c9f3db06a56">STARPU_PROFILING_ENABLE</a>. It is possible to detect whether monitoring is already enabled or not by calling <a class="el" href="group__API__Profiling.html#gaf014e2e050ebd38bc4cffec0081f96bf">starpu_profiling_status_get()</a>. Enabling monitoring also reinitialize all previously collected feedback. The environment variable <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_PROFILING">STARPU_PROFILING</a> can also be set to <code>1</code> to achieve the same effect. The function <a class="el" href="group__API__Profiling.html#ga6ab0a1e4a8a55e0c54e2151fd0a82a36">starpu_profiling_init()</a> can also be called during the execution to reinitialize performance counters and to start the profiling if the environment variable <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_PROFILING">STARPU_PROFILING</a> is set to <code>1</code>.</p>
<p>Likewise, performance monitoring is stopped by calling <a class="el" href="group__API__Profiling.html#gabeb22bbe8062a45507cfc6273aae51ae">starpu_profiling_status_set()</a> with the parameter <a class="el" href="group__API__Profiling.html#ga1e388939370daaf139c73678e413f00a">STARPU_PROFILING_DISABLE</a>. Note that this does not reset the performance counters so that the application may consult them later on.</p>
<p>More details about the performance monitoring API are available in <a class="el" href="group__API__Profiling.html">Profiling</a>.</p>
<h2><a class="anchor" id="Per-taskFeedback"></a>
Per-task Feedback</h2>
<p>If profiling is enabled, a pointer to a structure <a class="el" href="group__API__Profiling.html#structstarpu__profiling__task__info">starpu_profiling_task_info</a> is put in the field <a class="el" href="group__API__Codelet__And__Tasks.html#a7f9c6b6e848834c2e6001d8a8bd2ba21">starpu_task::profiling_info</a> when a task terminates. This structure is automatically destroyed when the task structure is destroyed, either automatically or by calling <a class="el" href="group__API__Codelet__And__Tasks.html#ga8fdfb4c2276013b699f5398a1c528bba">starpu_task_destroy()</a>.</p>
<p>The structure <a class="el" href="group__API__Profiling.html#structstarpu__profiling__task__info">starpu_profiling_task_info</a> indicates the date when the task was submitted (<a class="el" href="group__API__Profiling.html#a3a1a7c8e4ce2552a0f96a8dd4f9ad37f">starpu_profiling_task_info::submit_time</a>), started (<a class="el" href="group__API__Profiling.html#ab8de457be74df606d29c3efa1169998a">starpu_profiling_task_info::start_time</a>), and terminated (<a class="el" href="group__API__Profiling.html#ade189cd6175d789db1eb6bfad19b3e35">starpu_profiling_task_info::end_time</a>), relative to the initialization of StarPU with <a class="el" href="group__API__Initialization__and__Termination.html#ga9ce171bcbbee2edd169ba2649e6e75e3">starpu_init()</a>. It also specifies the identifier of the worker that has executed the task (<a class="el" href="group__API__Profiling.html#a19a06e7ef34a9a4587e77949ded36644">starpu_profiling_task_info::workerid</a>). These date are stored as <code>timespec</code> structures which the user may convert into micro-seconds using the helper function <a class="el" href="group__API__Profiling.html#ga87639260ff5c89f466e83fcc093e77fe">starpu_timing_timespec_to_us()</a>.</p>
<p>It it worth noting that the application may directly access this structure from the callback executed at the end of the task. The structure <a class="el" href="group__API__Codelet__And__Tasks.html#structstarpu__task">starpu_task</a> associated to the callback currently being executed is indeed accessible with the function <a class="el" href="group__API__Codelet__And__Tasks.html#ga1ccc2cbecd482eb1d3f9d2c27619d178">starpu_task_get_current()</a>.</p>
<h2><a class="anchor" id="Per-codeletFeedback"></a>
Per-codelet Feedback</h2>
<p>The field <a class="el" href="group__API__Codelet__And__Tasks.html#a24e7ec85b5c3c7800676db5c2061a71a">starpu_codelet::per_worker_stats</a> is an array of counters. The <code>i</code>-th entry of the array is incremented every time a task implementing the codelet is executed on the <code>i</code>-th worker. This array is not reinitialized when profiling is enabled or disabled.</p>
<h2><a class="anchor" id="Per-workerFeedback"></a>
Per-worker Feedback</h2>
<p>The second argument returned by the function <a class="el" href="group__API__Profiling.html#ga8a423df93ec48a7391b2f439357a5544">starpu_profiling_worker_get_info()</a> is a structure <a class="el" href="group__API__Profiling.html#structstarpu__profiling__worker__info">starpu_profiling_worker_info</a> that gives statistics about the specified worker. This structure specifies when StarPU started collecting profiling information for that worker (<a class="el" href="group__API__Profiling.html#aed6a8be9b919f03e093912bfc44c5559">starpu_profiling_worker_info::start_time</a>), the duration of the profiling measurement interval (<a class="el" href="group__API__Profiling.html#aae49335c3c189b58103cb649fc169096">starpu_profiling_worker_info::total_time</a>), the time spent executing kernels (<a class="el" href="group__API__Profiling.html#a050199a48e0073f892cd6dd9049a4edf">starpu_profiling_worker_info::executing_time</a>), the time spent sleeping because there is no task to execute at all (<a class="el" href="group__API__Profiling.html#acc882d8569e28d51fd5e820962fed773">starpu_profiling_worker_info::sleeping_time</a>), and the number of tasks that were executed while profiling was enabled. These values give an estimation of the proportion of time spent do real work, and the time spent either sleeping because there are not enough executable tasks or simply wasted in pure StarPU overhead.</p>
<p>Calling <a class="el" href="group__API__Profiling.html#ga8a423df93ec48a7391b2f439357a5544">starpu_profiling_worker_get_info()</a> resets the profiling information associated to a worker.</p>
<p>To easily display all this information, the environment variable <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_WORKER_STATS">STARPU_WORKER_STATS</a> can be set to <code>1</code> (in addition to setting <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_PROFILING">STARPU_PROFILING</a> to 1). A summary will then be displayed at program termination. To display the summary in a file instead of the standard error stream, use the environment variable <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_WORKER_STATS_FILE">STARPU_WORKER_STATS_FILE</a>.</p>
<pre class="fragment">Worker stats:
CUDA 0.0 (4.7 GiB)
	480 task(s)
	total: 1574.82 ms executing: 1510.72 ms sleeping: 0.00 ms overhead 64.10 ms
	325.217970 GFlop/s

CPU 0
	22 task(s)
	total: 1574.82 ms executing: 1364.81 ms sleeping: 0.00 ms overhead 210.01 ms
	7.512057 GFlop/s

CPU 1
	14 task(s)
	total: 1574.82 ms executing: 1500.13 ms sleeping: 0.00 ms overhead 74.69 ms
	6.675853 GFlop/s

CPU 2
	14 task(s)
	total: 1574.82 ms executing: 1553.12 ms sleeping: 0.00 ms overhead 21.70 ms
	7.152886 GFlop/s
</pre><p>The number of GFlops/s is available because the <a class="el" href="group__API__Codelet__And__Tasks.html#a840563895dbf036b6ffd783a8ea2504d">starpu_task::flops</a> field of the tasks were filled (or <a class="el" href="group__API__Insert__Task.html#ga1a0a565f2de522abc9c5f3457397b095">STARPU_FLOPS</a> used in <a class="el" href="group__API__Insert__Task.html#gad79a50a21fe717126659b2998209c1c6">starpu_task_insert()</a>).</p>
<p>When an FxT trace is generated (see <a class="el" href="OfflinePerformanceTools.html#GeneratingTracesWithFxT">Generating Traces With FxT</a>), it is also possible to use the tool <code>starpu_workers_activity</code> (see <a class="el" href="OfflinePerformanceTools.html#MonitoringActivity">Monitoring Activity</a>) to generate a graphic showing the evolution of these values during the time, for the different workers.</p>
<h2><a class="anchor" id="Bus-relatedFeedback"></a>
Bus-related Feedback</h2>
<p>The bus speed measured by StarPU can be displayed by using the tool <code>starpu_machine_display</code>, for instance:</p>
<pre class="fragment">StarPU has found:
        3 CUDA devices
                CUDA 0 (Tesla C2050 02:00.0)
                CUDA 1 (Tesla C2050 03:00.0)
                CUDA 2 (Tesla C2050 84:00.0)
from    to RAM          to CUDA 0       to CUDA 1       to CUDA 2
RAM     0.000000        5176.530428     5176.492994     5191.710722
CUDA 0  4523.732446     0.000000        2414.074751     2417.379201
CUDA 1  4523.718152     2414.078822     0.000000        2417.375119
CUDA 2  4534.229519     2417.069025     2417.060863     0.000000
</pre><p>Statistics about the data transfers which were performed and temporal average of bandwidth usage can be obtained by setting the environment variable <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_BUS_STATS">STARPU_BUS_STATS</a> to <code>1</code>; a summary will then be displayed at program termination. To display the summary in a file instead of the standard error stream, use the environment variable <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_BUS_STATS_FILE">STARPU_BUS_STATS_FILE</a>.</p>
<pre class="fragment">Data transfer stats:
	RAM 0 -&gt; CUDA 0	319.92 MB	213.10 MB/s	(transfers : 91 - avg 3.52 MB)
	CUDA 0 -&gt; RAM 0	214.45 MB	142.85 MB/s	(transfers : 61 - avg 3.52 MB)
	RAM 0 -&gt; CUDA 1	302.34 MB	201.39 MB/s	(transfers : 86 - avg 3.52 MB)
	CUDA 1 -&gt; RAM 0	133.59 MB	88.99 MB/s	(transfers : 38 - avg 3.52 MB)
	CUDA 0 -&gt; CUDA 1	144.14 MB	96.01 MB/s	(transfers : 41 - avg 3.52 MB)
	CUDA 1 -&gt; CUDA 0	130.08 MB	86.64 MB/s	(transfers : 37 - avg 3.52 MB)
	RAM 0 -&gt; CUDA 2	312.89 MB	208.42 MB/s	(transfers : 89 - avg 3.52 MB)
	CUDA 2 -&gt; RAM 0	133.59 MB	88.99 MB/s	(transfers : 38 - avg 3.52 MB)
	CUDA 0 -&gt; CUDA 2	151.17 MB	100.69 MB/s	(transfers : 43 - avg 3.52 MB)
	CUDA 2 -&gt; CUDA 0	105.47 MB	70.25 MB/s	(transfers : 30 - avg 3.52 MB)
	CUDA 1 -&gt; CUDA 2	175.78 MB	117.09 MB/s	(transfers : 50 - avg 3.52 MB)
	CUDA 2 -&gt; CUDA 1	203.91 MB	135.82 MB/s	(transfers : 58 - avg 3.52 MB)
Total transfers: 2.27 GB
</pre><h2><a class="anchor" id="MPI-relatedFeedback"></a>
MPI-related Feedback</h2>
<p>Statistics about the data transfers which were performed over MPI can be obtained by setting the environment variable <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_COMM_STATS">STARPU_COMM_STATS</a> to <code>1</code>; a summary will then be displayed at program termination:</p>
<pre class="fragment">[starpu_comm_stats][1] TOTAL:	456.000000 B	0.000435 MB	 0.000188 B/s	 0.000000 MB/s
[starpu_comm_stats][1:0]	456.000000 B	0.000435 MB	 0.000188 B/s	 0.000000 MB/s

[starpu_comm_stats][0] TOTAL:	456.000000 B	0.000435 MB	 0.000188 B/s	 0.000000 MB/s
[starpu_comm_stats][0:1]	456.000000 B	0.000435 MB	 0.000188 B/s	 0.000000 MB/s
</pre><p>These statistics can be plotted as heatmaps using StarPU tool <code>starpu_mpi_comm_matrix.py</code> (see <a class="el" href="MPISupport.html#MPIDebug">Debugging MPI</a>).</p>
<h1><a class="anchor" id="TaskAndWorkerProfiling"></a>
Task And Worker Profiling</h1>
<p>A full example showing how to use the profiling API is available in the StarPU sources in the directory <code>examples/profiling/</code>.</p>
<div class="fragment"><div class="line"><span class="keyword">struct </span><a class="code" href="group__API__Codelet__And__Tasks.html#structstarpu__task">starpu_task</a> *task = <a class="code" href="group__API__Codelet__And__Tasks.html#ga042d3b1b8083e49f2977f5032fda938c">starpu_task_create</a>();</div><div class="line">task-&gt;<a class="code" href="group__API__Codelet__And__Tasks.html#ac0e8ab897e436b244f13ec17b1191062">cl</a> = &amp;<a class="code" href="group__API__Codelet__And__Tasks.html#ac0e8ab897e436b244f13ec17b1191062">cl</a>;</div><div class="line">task-&gt;<a class="code" href="group__API__Codelet__And__Tasks.html#a18439d7a6d4ad65b75c75ec02d60075e">synchronous</a> = 1;</div><div class="line"><span class="comment">/* We will destroy the task structure by hand so that we can</span></div><div class="line"><span class="comment"> * query the profiling info before the task is destroyed. */</span></div><div class="line">task-&gt;<a class="code" href="group__API__Codelet__And__Tasks.html#a3ee97849eb5c84df12676547d5c48aaf">destroy</a> = 0;</div><div class="line"></div><div class="line"><span class="comment">/* Submit and wait for completion (since synchronous was set to 1) */</span></div><div class="line"><a class="code" href="group__API__Codelet__And__Tasks.html#gaa32228bf7f452f7d664986668ea46590">starpu_task_submit</a>(task);</div><div class="line"></div><div class="line"><span class="comment">/* The task is finished, get profiling information */</span></div><div class="line"><span class="keyword">struct </span><a class="code" href="group__API__Profiling.html#structstarpu__profiling__task__info">starpu_profiling_task_info</a> *info = task-&gt;<a class="code" href="group__API__Codelet__And__Tasks.html#a7f9c6b6e848834c2e6001d8a8bd2ba21">profiling_info</a>;</div><div class="line"></div><div class="line"><span class="comment">/* How much time did it take before the task started ? */</span></div><div class="line"><span class="keywordtype">double</span> delay += <a class="code" href="group__API__Profiling.html#gacf0b5499290848f07c97a32c6c2412db">starpu_timing_timespec_delay_us</a>(&amp;info-&gt;<a class="code" href="group__API__Profiling.html#a3a1a7c8e4ce2552a0f96a8dd4f9ad37f">submit_time</a>, &amp;info-&gt;<a class="code" href="group__API__Profiling.html#ab8de457be74df606d29c3efa1169998a">start_time</a>);</div><div class="line"></div><div class="line"><span class="comment">/* How long was the task execution ? */</span></div><div class="line"><span class="keywordtype">double</span> length += <a class="code" href="group__API__Profiling.html#gacf0b5499290848f07c97a32c6c2412db">starpu_timing_timespec_delay_us</a>(&amp;info-&gt;<a class="code" href="group__API__Profiling.html#ab8de457be74df606d29c3efa1169998a">start_time</a>, &amp;info-&gt;<a class="code" href="group__API__Profiling.html#ade189cd6175d789db1eb6bfad19b3e35">end_time</a>);</div><div class="line"></div><div class="line"><span class="comment">/* We no longer need the task structure */</span></div><div class="line"><a class="code" href="group__API__Codelet__And__Tasks.html#ga8fdfb4c2276013b699f5398a1c528bba">starpu_task_destroy</a>(task);</div></div><!-- fragment --><div class="fragment"><div class="line"><span class="comment">/* Display the occupancy of all workers during the test */</span></div><div class="line"><span class="keywordtype">int</span> worker;</div><div class="line"><span class="keywordflow">for</span> (worker = 0; worker &lt; <a class="code" href="group__API__Workers__Properties.html#ga6312aa4b12ce7e06fe391bcafda6796a">starpu_worker_get_count</a>(); worker++)</div><div class="line">{</div><div class="line">        <span class="keyword">struct </span><a class="code" href="group__API__Profiling.html#structstarpu__profiling__worker__info">starpu_profiling_worker_info</a> worker_info;</div><div class="line">        <span class="keywordtype">int</span> ret = <a class="code" href="group__API__Profiling.html#ga8a423df93ec48a7391b2f439357a5544">starpu_profiling_worker_get_info</a>(worker, &amp;worker_info);</div><div class="line">        <a class="code" href="group__API__Toolbox.html#ga05ac0dda104331f57d85823a4f9318ce">STARPU_ASSERT</a>(!ret);</div><div class="line"></div><div class="line">        <span class="keywordtype">double</span> <a class="code" href="group__API__Profiling.html#aae49335c3c189b58103cb649fc169096">total_time</a> = <a class="code" href="group__API__Profiling.html#ga87639260ff5c89f466e83fcc093e77fe">starpu_timing_timespec_to_us</a>(&amp;worker_info.total_time);</div><div class="line">        <span class="keywordtype">double</span> <a class="code" href="group__API__Profiling.html#a050199a48e0073f892cd6dd9049a4edf">executing_time</a> = <a class="code" href="group__API__Profiling.html#ga87639260ff5c89f466e83fcc093e77fe">starpu_timing_timespec_to_us</a>(&amp;worker_info.executing_time);</div><div class="line">        <span class="keywordtype">double</span> <a class="code" href="group__API__Profiling.html#acc882d8569e28d51fd5e820962fed773">sleeping_time</a> = <a class="code" href="group__API__Profiling.html#ga87639260ff5c89f466e83fcc093e77fe">starpu_timing_timespec_to_us</a>(&amp;worker_info.sleeping_time);</div><div class="line">        <span class="keywordtype">double</span> overhead_time = total_time - executing_time - <a class="code" href="group__API__Profiling.html#acc882d8569e28d51fd5e820962fed773">sleeping_time</a>;</div><div class="line"></div><div class="line">        <span class="keywordtype">float</span> executing_ratio = 100.0*executing_time/<a class="code" href="group__API__Profiling.html#aae49335c3c189b58103cb649fc169096">total_time</a>;</div><div class="line">        <span class="keywordtype">float</span> sleeping_ratio = 100.0*sleeping_time/<a class="code" href="group__API__Profiling.html#aae49335c3c189b58103cb649fc169096">total_time</a>;</div><div class="line">        <span class="keywordtype">float</span> overhead_ratio = 100.0 - executing_ratio - sleeping_ratio;</div><div class="line"></div><div class="line">        <span class="keywordtype">char</span> workername[128];</div><div class="line">        <a class="code" href="group__API__Workers__Properties.html#gae35a841f996b8758f3d0ce2ac2d066a5">starpu_worker_get_name</a>(worker, workername, 128);</div><div class="line">        fprintf(stderr, <span class="stringliteral">&quot;Worker %s:\n&quot;</span>, workername);</div><div class="line">        fprintf(stderr, <span class="stringliteral">&quot;\ttotal time: %.2lf ms\n&quot;</span>, total_time*1e-3);</div><div class="line">        fprintf(stderr, <span class="stringliteral">&quot;\texec time: %.2lf ms (%.2f %%)\n&quot;</span>, executing_time*1e-3, executing_ratio);</div><div class="line">        fprintf(stderr, <span class="stringliteral">&quot;\tblocked time: %.2lf ms (%.2f %%)\n&quot;</span>, sleeping_time*1e-3, sleeping_ratio);</div><div class="line">        fprintf(stderr, <span class="stringliteral">&quot;\toverhead time: %.2lf ms (%.2f %%)\n&quot;</span>, overhead_time*1e-3, overhead_ratio);</div><div class="line">}</div></div><!-- fragment --><h1><a class="anchor" id="PerformanceModelExample"></a>
Performance Model Example</h1>
<p>To achieve good scheduling, StarPU scheduling policies need to be able to estimate in advance the duration of a task. This is done by giving to codelets a performance model, by defining a structure <a class="el" href="group__API__Performance__Model.html#structstarpu__perfmodel">starpu_perfmodel</a> and providing its address in the field <a class="el" href="group__API__Codelet__And__Tasks.html#a23ebb598b9065c98cc198e2f7b62fdde">starpu_codelet::model</a>. The fields <a class="el" href="group__API__Performance__Model.html#a114aa08286b9f6158aa9262c995d9bcd">starpu_perfmodel::symbol</a> and <a class="el" href="group__API__Performance__Model.html#afe2d561aaba7bf1ad1cf03974ee8c53c">starpu_perfmodel::type</a> are mandatory, to give a name to the model, and the type of the model, since there are several kinds of performance models. For compatibility, make sure to initialize the whole structure to zero, either by using explicit memset(), or by letting the compiler implicitly do it as examplified below.</p>
<ul>
<li>
<p class="startli">Measured at runtime (model type <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6ab1ea457716c143f155593a2112e38f35">STARPU_HISTORY_BASED</a>). This assumes that for a given set of data input/output sizes, the performance will always be about the same. This is very true for regular kernels on GPUs for instance (&lt;0.1% error), and just a bit less true on CPUs (~=1% error). This also assumes that there are few different sets of data input/output sizes. StarPU will then keep record of the average time of previous executions on the various processing units, and use it as an estimation. History is done per task size, by using a hash of the input and ouput sizes as an index. It will also save it in <code>$STARPU_HOME/.starpu/sampling/codelets</code> for further executions, and can be observed by using the tool <code>starpu_perfmodel_display</code>, or drawn by using the tool <code>starpu_perfmodel_plot</code> (<a class="el" href="CheckListWhenPerformanceAreNotThere.html#PerformanceModelCalibration">Performance Model Calibration</a>). The models are indexed by machine name. To share the models between machines (e.g. for a homogeneous cluster), use <code>export STARPU_HOSTNAME=some_global_name</code>. Measurements are only done when using a task scheduler which makes use of it, such as <code>dmda</code>. Measurements can also be provided explicitly by the application, by using the function <a class="el" href="group__API__Performance__Model.html#gaecb9341bff471557abbb63a966449481">starpu_perfmodel_update_history()</a>.</p>
<p>The following is a small code example.</p>
<p>If e.g. the code is recompiled with other compilation options, or several variants of the code are used, the <code>symbol</code> string should be changed to reflect that, in order to recalibrate a new model from zero. The <code>symbol</code> string can even be constructed dynamically at execution time, as long as this is done before submitting any task using it.</p>
<div class="fragment"><div class="line"><span class="keyword">static</span> <span class="keyword">struct </span><a class="code" href="group__API__Performance__Model.html#structstarpu__perfmodel">starpu_perfmodel</a> mult_perf_model =</div><div class="line">{</div><div class="line">    .<a class="code" href="group__API__Performance__Model.html#afe2d561aaba7bf1ad1cf03974ee8c53c">type</a> = <a class="code" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6ab1ea457716c143f155593a2112e38f35">STARPU_HISTORY_BASED</a>,</div><div class="line">    .symbol = <span class="stringliteral">&quot;mult_perf_model&quot;</span></div><div class="line">};</div><div class="line"></div><div class="line"><span class="keyword">struct </span><a class="code" href="group__API__Codelet__And__Tasks.html#structstarpu__codelet">starpu_codelet</a> cl =</div><div class="line">{</div><div class="line">    .<a class="code" href="group__API__Codelet__And__Tasks.html#a593418a8961318e4085177abeeaa43ad">cpu_funcs</a> = { cpu_mult },</div><div class="line">    .cpu_funcs_name = { <span class="stringliteral">&quot;cpu_mult&quot;</span> },</div><div class="line">    .nbuffers = 3,</div><div class="line">    .modes = { <a class="code" href="group__API__Data__Management.html#gga1fb3a1ff8622747d653d1b5f41bc41dbaab55b4cef9cfedeacae7012cd52e5389">STARPU_R</a>, <a class="code" href="group__API__Data__Management.html#gga1fb3a1ff8622747d653d1b5f41bc41dbaab55b4cef9cfedeacae7012cd52e5389">STARPU_R</a>, <a class="code" href="group__API__Data__Management.html#gga1fb3a1ff8622747d653d1b5f41bc41dba628e5483f4cb6e44779aea39300dafed">STARPU_W</a> },</div><div class="line">    <span class="comment">/* for the scheduling policy to be able to use performance models */</span></div><div class="line">    .model = &amp;mult_perf_model</div><div class="line">};</div></div><!-- fragment --><p class="endli"></p>
</li>
<li>
<p class="startli">Measured at runtime and refined by regression (model types <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6a58209f94a343ef0a116881cae2a3a405">STARPU_REGRESSION_BASED</a> and <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6a286175813689c4623e1558ed7fe317f5">STARPU_NL_REGRESSION_BASED</a>). This still assumes performance regularity, but works with various data input sizes, by applying regression over observed execution times. <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6a58209f94a343ef0a116881cae2a3a405">STARPU_REGRESSION_BASED</a> uses an <code>a*n^b</code> regression form, <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6a286175813689c4623e1558ed7fe317f5">STARPU_NL_REGRESSION_BASED</a> uses an <code>a*n^b+c</code> (more precise than <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6a58209f94a343ef0a116881cae2a3a405">STARPU_REGRESSION_BASED</a>, but costs a lot more to compute).</p>
<p>For instance, <code>tests/perfmodels/regression_based.c</code> uses a regression-based performance model for the function memset().</p>
<p>Of course, the application has to issue tasks with varying size so that the regression can be computed. StarPU will not trust the regression unless there is at least 10% difference between the minimum and maximum observed input size. It can be useful to set the environment variable <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_CALIBRATE">STARPU_CALIBRATE</a> to <code>1</code> and run the application on varying input sizes with <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_SCHED">STARPU_SCHED</a> set to <code>dmda</code> scheduler, so as to feed the performance model for a variety of inputs. The application can also provide the measurements explictly by using the function <a class="el" href="group__API__Performance__Model.html#gaecb9341bff471557abbb63a966449481">starpu_perfmodel_update_history()</a>. The tools <code>starpu_perfmodel_display</code> and <code>starpu_perfmodel_plot</code> can be used to observe how much the performance model is calibrated (<a class="el" href="CheckListWhenPerformanceAreNotThere.html#PerformanceModelCalibration">Performance Model Calibration</a>); when their output look good, <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_CALIBRATE">STARPU_CALIBRATE</a> can be reset to <code>0</code> to let StarPU use the resulting performance model without recording new measures, and <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_SCHED">STARPU_SCHED</a> can be set to <code>dmda</code> to benefit from the performance models. If the data input sizes vary a lot, it is really important to set <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_CALIBRATE">STARPU_CALIBRATE</a> to <code>0</code>, otherwise StarPU will continue adding the measures, and result with a very big performance model, which will take time a lot of time to load and save.</p>
<p>For non-linear regression, since computing it is quite expensive, it is only done at termination of the application. This means that the first execution of the application will use only history-based performance model to perform scheduling, without using regression. </p>
<p class="endli"></p>
</li>
<li>
<p class="startli"></p>
<p>Another type of model is <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6a4c58334b6de6683d02d9d927e1dba901">STARPU_MULTIPLE_REGRESSION_BASED</a>, which is based on multiple linear regression. In this model, the user defines both the relevant parameters and the equation for computing the task duration.</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ T_{kernel} = a + b(M^{\alpha_1} * N^{\beta_1} * K^{\gamma_1}) + c(M^{\alpha_2} * N^{\beta_2} * K^{\gamma_2}) + ... \]" src="form_0.png"/>
</p>
<p><img class="formulaInl" alt="$M, N, K$" src="form_1.png"/> are the parameters of the task, added at the task creation. These need to be extracted by the <code>cl_perf_func</code> function, which should be defined by the user. <img class="formulaInl" alt="$\alpha, \beta, \gamma$" src="form_2.png"/> are the exponents defined by the user in <code>model-&gt;combinations</code> table. Finally, coefficients <img class="formulaInl" alt="$a, b, c$" src="form_3.png"/> are computed automatically by the StarPU at the end of the execution, using least squares method of the <code>dgels_</code> LAPACK function.</p>
<p><code>examples/mlr/mlr.c</code> example provides more details on the usage of <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6a4c58334b6de6683d02d9d927e1dba901">STARPU_MULTIPLE_REGRESSION_BASED</a> models. The <a class="el" href="CompilationConfiguration.html#enable-mlr">--enable-mlr</a> configure option needs to be set to calibrate the model.</p>
<p>Coefficients computation is done at the end of the execution, and the results are stored in standard codelet perfmodel files. Additional files containing the duration of task together with the value of each parameter are stored in <code>.starpu/sampling/codelets/tmp/</code> directory. These files are reused when <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_CALIBRATE">STARPU_CALIBRATE</a> environment variable is set to <code>1</code>, to recompute coefficients based on the current, but also on the previous executions. By default StarPU uses a lightweight dgels implementation, but the <a class="el" href="CompilationConfiguration.html#enable-mlr-system-blas">--enable-mlr-system-blas</a> configure option can be used to make StarPU use a system-provided dgels BLAS.</p>
<p>Additionally, when multiple linear regression models are not enabled through <a class="el" href="CompilationConfiguration.html#enable-mlr">--enable-mlr</a> or when the <code>model-&gt;combinations</code> are not defined, StarPU will still write output files into <code>.starpu/sampling/codelets/tmp/</code> to allow performing an analysis. This analysis typically aims at finding the most appropriate equation for the codelet and <code>tools/starpu_mlr_analysis</code> script provides an example of how to perform such study.</p>
<p></p>
<p class="endli"></p>
</li>
<li>
<p class="startli">Provided as an estimation from the application itself (model type <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6a626db2177027908d7d6f4753807bca8b">STARPU_COMMON</a> and field <a class="el" href="group__API__Performance__Model.html#a16967b7c8c6860d283fc7db434cd3c7c">starpu_perfmodel::cost_function</a>), see for instance <code>examples/common/blas_model.h</code> and <code>examples/common/blas_model.c</code>. </p>
<p class="endli"></p>
</li>
<li>
Provided explicitly by the application (model type <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6a98a0f2cda640f231009f262e676f4851">STARPU_PER_ARCH</a>): either field <a class="el" href="group__API__Performance__Model.html#a4efccf0f3badb8eb35a07704b0e3ef01">starpu_perfmodel::arch_cost_function</a>, or the fields <code>.per_arch[arch][nimpl].cost_function</code> have to be filled with pointers to functions which return the expected duration of the task in micro-seconds, one per architecture, see for instance <code>tests/datawizard/locality.c</code>  </li>
</ul>
<p>For <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6ab1ea457716c143f155593a2112e38f35">STARPU_HISTORY_BASED</a>, <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6a58209f94a343ef0a116881cae2a3a405">STARPU_REGRESSION_BASED</a>, and <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6a286175813689c4623e1558ed7fe317f5">STARPU_NL_REGRESSION_BASED</a>, the dimensions of task data (both input and output) are used as an index by default. <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6ab1ea457716c143f155593a2112e38f35">STARPU_HISTORY_BASED</a> uses a CRC hash of the dimensions as an index to distinguish histories, and <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6a58209f94a343ef0a116881cae2a3a405">STARPU_REGRESSION_BASED</a> and <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6a286175813689c4623e1558ed7fe317f5">STARPU_NL_REGRESSION_BASED</a> use the total size as an index for the regression.</p>
<p>The <a class="el" href="group__API__Performance__Model.html#a861b8ed68d4562e477948ee1ec511645">starpu_perfmodel::size_base</a> and <a class="el" href="group__API__Performance__Model.html#a40bcf4bf061be8c34ee0e418a8f5f27a">starpu_perfmodel::footprint</a> fields however permit the application to override that, when for instance some of the data do not matter for task cost (e.g. mere reference table), or when using sparse structures (in which case it is the number of non-zeros which matter), or when there is some hidden parameter such as the number of iterations, or when the application actually has a very good idea of the complexity of the algorithm, and just not the speed of the processor, etc. The example in the directory <code>examples/pi</code> uses this to include the number of iterations in the base size. <a class="el" href="group__API__Performance__Model.html#a861b8ed68d4562e477948ee1ec511645">starpu_perfmodel::size_base</a> should be used when the variance of the actual performance is known (i.e. bigger return value is longer execution time), and thus particularly useful for <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6a58209f94a343ef0a116881cae2a3a405">STARPU_REGRESSION_BASED</a> or <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6a286175813689c4623e1558ed7fe317f5">STARPU_NL_REGRESSION_BASED</a>. <a class="el" href="group__API__Performance__Model.html#a40bcf4bf061be8c34ee0e418a8f5f27a">starpu_perfmodel::footprint</a> can be used when the variance of the actual performance is unknown (irregular performance behavior, etc.), and thus only useful for <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6ab1ea457716c143f155593a2112e38f35">STARPU_HISTORY_BASED</a>. <a class="el" href="group__API__Scheduling__Policy.html#gaa859b0ee59cfa2bde4d241f854c3bbea">starpu_task_data_footprint()</a> can be used as a base and combined with other parameters through <a class="el" href="group__API__Data__Interfaces.html#gaa29d5f4bd11fce82cd9a01b0e860bf75">starpu_hash_crc32c_be()</a> for instance.</p>
<p>StarPU will automatically determine when the performance model is calibrated, or rather, it will assume the performance model is calibrated until the application submits a task for which the performance can not be predicted. For <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6ab1ea457716c143f155593a2112e38f35">STARPU_HISTORY_BASED</a>, StarPU will require 10 (STARPU_CALIBRATE_MINIMUM) measurements for a given size before estimating that an average can be taken as estimation for further executions with the same size. For <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6a58209f94a343ef0a116881cae2a3a405">STARPU_REGRESSION_BASED</a> and <a class="el" href="group__API__Performance__Model.html#ggae161a7cae376f3fc831a2b764e8144e6a286175813689c4623e1558ed7fe317f5">STARPU_NL_REGRESSION_BASED</a>, StarPU will require 10 (STARPU_CALIBRATE_MINIMUM) measurements, and that the minimum measured data size is smaller than 90% of the maximum measured data size (i.e. the measurement interval is large enough for a regression to have a meaning). Calibration can also be forced by setting the <a class="el" href="ExecutionConfigurationThroughEnvironmentVariables.html#STARPU_CALIBRATE">STARPU_CALIBRATE</a> environment variable to <code>1</code>, or even reset by setting it to <code>2</code>.</p>
<p>How to use schedulers which can benefit from such performance model is explained in <a class="el" href="Scheduling.html#TaskSchedulingPolicy">Task Scheduling Policies</a>.</p>
<p>The same can be done for task energy consumption estimation, by setting the field <a class="el" href="group__API__Codelet__And__Tasks.html#af8fa998af7fac8cea705533162dcbf35">starpu_codelet::energy_model</a> the same way as the field <a class="el" href="group__API__Codelet__And__Tasks.html#a23ebb598b9065c98cc198e2f7b62fdde">starpu_codelet::model</a>. Note: for now, the application has to give to the energy consumption performance model a name which is different from the execution time performance model.</p>
<p>The application can request time estimations from the StarPU performance models by filling a task structure as usual without actually submitting it. The data handles can be created by calling any of the functions <code>starpu_*_data_register</code> with a <code>NULL</code> pointer and <code>-1</code> node and the desired data sizes, and need to be unregistered as usual. The functions <a class="el" href="group__API__Scheduling__Policy.html#ga2dc83adec9e479e967a1d1c2ae40f916">starpu_task_expected_length()</a> and <a class="el" href="group__API__Scheduling__Policy.html#ga3e9efb4ca2cbc1c74757e0a9cb0f26c6">starpu_task_expected_energy()</a> can then be called to get an estimation of the task cost on a given arch. <a class="el" href="group__API__Scheduling__Policy.html#ga21385d19bc75a7581e774bd455c70790">starpu_task_footprint()</a> can also be used to get the footprint used for indexing history-based performance models. <a class="el" href="group__API__Codelet__And__Tasks.html#ga8fdfb4c2276013b699f5398a1c528bba">starpu_task_destroy()</a> needs to be called to destroy the dummy task afterwards. See <code>tests/perfmodels/regression_based.c</code> for an example.</p>
<p>The application can also request an on-the-fly XML report of the performance model, by calling <a class="el" href="group__API__Performance__Model.html#gaac6a7d27c0033f882722892237e82d82">starpu_perfmodel_dump_xml()</a> to print the report to a <code>FILE*</code>. </p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Fri Oct 22 2021 15:02:13 for StarPU Handbook by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
